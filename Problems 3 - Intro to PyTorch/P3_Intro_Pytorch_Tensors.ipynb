{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkaratzas/DL2022-23/blob/main/Problems%202%20-%20Using%20Autograd%20and%20PyTorch/P2_2_Intro_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcvesegFyIX-"
      },
      "source": [
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/dkaratzas/DL2022-23/blob/main/Problems%202%20-%20Using%20Autograd%20and%20PyTorch/P2_2_Intro_Tensors.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IF4i31_7jbg"
      },
      "source": [
        "# What is PyTorch?\n",
        "\n",
        "<a href=\"https://pytorch.org/\">Pytorch</a> is a Python based scientific computing package targeted at two types of audience:\n",
        "\n",
        "-  At the low level, it is a tensor library capable to exploit the computational power of GPUs\n",
        "-  At the high level, it is a deep learning research platform that provides maximum flexibility and speed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ng2mpMYgkpu"
      },
      "source": [
        "## Import the library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FzX92S587jbm"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y62dQH467jbn"
      },
      "source": [
        "## Getting help in Jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll9zxJ9IyIYB"
      },
      "source": [
        "The fastest way to get some quick help on something using Jupyter is to just ask! Type any Python object name you want followed by a question mark `?` and the code documentation will be loaded in your notebook. Try it with `torch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LN6xGdhUyIYB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mType:\u001b[0m        module\n",
            "\u001b[0;31mString form:\u001b[0m <module 'torch' from '/nix/store/8gmhah54y2p2r01hd0xnmdkvwh03819a-python3.12-torch-2.5.1/lib/python3.12/site-packages/torch/__init__.py'>\n",
            "\u001b[0;31mFile:\u001b[0m        /nix/store/8gmhah54y2p2r01hd0xnmdkvwh03819a-python3.12-torch-2.5.1/lib/python3.12/site-packages/torch/__init__.py\n",
            "\u001b[0;31mDocstring:\u001b[0m  \n",
            "The torch package contains data structures for multi-dimensional\n",
            "tensors and defines mathematical operations over these tensors.\n",
            "Additionally, it provides many utilities for efficient serialization of\n",
            "Tensors and arbitrary types, and other useful utilities.\n",
            "\n",
            "It has a CUDA counterpart, that enables you to run your tensor computations\n",
            "on an NVIDIA GPU with compute capability >= 3.0."
          ]
        }
      ],
      "source": [
        "torch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLMcdjjuyIYB"
      },
      "source": [
        "The following command will list all objects of torch that with a name that finishes with \"Tensor\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BIqY0-QT7jbo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.BFloat16Tensor\n",
            "torch.BoolTensor\n",
            "torch.ByteTensor\n",
            "torch.CharTensor\n",
            "torch.DoubleTensor\n",
            "torch.FloatTensor\n",
            "torch.HalfTensor\n",
            "torch.IntTensor\n",
            "torch.LongTensor\n",
            "torch.ShortTensor\n",
            "torch.Tensor"
          ]
        }
      ],
      "source": [
        "# In Colab, you can press <esc> to get out of help\n",
        "torch.*Tensor?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpLRB9CFyIYC"
      },
      "source": [
        "If you use Colab, you also have a handy autocomplete feature at hand. For example, start writing a function name, like `torch.sqrt` if you pause after the first few characters a context menu with possible options will appear. Select the term you meant and press Tab or Enter to autocomplete. Note, this will not work in Jupyter Lab / Notebook out of the box, you would need to install an extension to enable this functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4g-D23eg7jbn"
      },
      "outputs": [],
      "source": [
        "# start typing torch.sqr...  wait and then use <Tab> or <Enter> to autocomplete to torch.sqrt()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcGTutwryIYD"
      },
      "source": [
        "In Jupyter Lab (but not in CoLab) you can access the documentation by clicking on the Python object and pressing `<Shift>` + `<Tab>`. Try it in the line below (if you are using Jupyter Lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED3Z0RKO7jbo",
        "outputId": "4a8fc200-c0c6-4af2-8bae-848d4ea728b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Module()"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.nn.Module()  # <Shift>+<Tab>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGLfjLTgyIYD"
      },
      "source": [
        "You should see the same result as with the line below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vrBufY4q7jbo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDocstring:\u001b[0m     \n",
            "Base class for all neural network modules.\n",
            "\n",
            "Your models should also subclass this class.\n",
            "\n",
            "Modules can also contain other Modules, allowing to nest them in\n",
            "a tree structure. You can assign the submodules as regular attributes::\n",
            "\n",
            "    import torch.nn as nn\n",
            "    import torch.nn.functional as F\n",
            "\n",
            "    class Model(nn.Module):\n",
            "        def __init__(self) -> None:\n",
            "            super().__init__()\n",
            "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
            "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
            "\n",
            "        def forward(self, x):\n",
            "            x = F.relu(self.conv1(x))\n",
            "            return F.relu(self.conv2(x))\n",
            "\n",
            "Submodules assigned in this way will be registered, and will have their\n",
            "parameters converted too when you call :meth:`to`, etc.\n",
            "\n",
            ".. note::\n",
            "    As per the example above, an ``__init__()`` call to the parent class\n",
            "    must be made before assignment on the child.\n",
            "\n",
            ":ivar training: Boolean represents whether this module is in training or\n",
            "                evaluation mode.\n",
            ":vartype training: bool\n",
            "\u001b[0;31mInit docstring:\u001b[0m Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
            "\u001b[0;31mFile:\u001b[0m           /nix/store/8gmhah54y2p2r01hd0xnmdkvwh03819a-python3.12-torch-2.5.1/lib/python3.12/site-packages/torch/nn/modules/module.py\n",
            "\u001b[0;31mType:\u001b[0m           type\n",
            "\u001b[0;31mSubclasses:\u001b[0m     Identity, Linear, Bilinear, Threshold, ReLU, RReLU, Hardtanh, Sigmoid, Hardsigmoid, Tanh, ..."
          ]
        }
      ],
      "source": [
        "# Annotate your functions / classes!\n",
        "torch.nn.Module?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQjnow2DyIYE"
      },
      "source": [
        "Where does this documentation come from? Part of it comes from the code itself, and part of it from the annotations (special comments) that are introduced in the function / class definitions. To have a look at the actual code of a function, just use a double `??`. See for example below, and get used to annotating your functions / classes as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k6gVzBNi7jbp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSource:\u001b[0m        \n",
            "\u001b[0;32mclass\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"Base class for all neural network modules.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m    Your models should also subclass this class.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m    Modules can also contain other Modules, allowing to nest them in\u001b[0m\n",
            "\u001b[0;34m    a tree structure. You can assign the submodules as regular attributes::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        import torch.nn as nn\u001b[0m\n",
            "\u001b[0;34m        import torch.nn.functional as F\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        class Model(nn.Module):\u001b[0m\n",
            "\u001b[0;34m            def __init__(self) -> None:\u001b[0m\n",
            "\u001b[0;34m                super().__init__()\u001b[0m\n",
            "\u001b[0;34m                self.conv1 = nn.Conv2d(1, 20, 5)\u001b[0m\n",
            "\u001b[0;34m                self.conv2 = nn.Conv2d(20, 20, 5)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            def forward(self, x):\u001b[0m\n",
            "\u001b[0;34m                x = F.relu(self.conv1(x))\u001b[0m\n",
            "\u001b[0;34m                return F.relu(self.conv2(x))\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m    Submodules assigned in this way will be registered, and will have their\u001b[0m\n",
            "\u001b[0;34m    parameters converted too when you call :meth:`to`, etc.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m    .. note::\u001b[0m\n",
            "\u001b[0;34m        As per the example above, an ``__init__()`` call to the parent class\u001b[0m\n",
            "\u001b[0;34m        must be made before assignment on the child.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m    :ivar training: Boolean represents whether this module is in training or\u001b[0m\n",
            "\u001b[0;34m                    evaluation mode.\u001b[0m\n",
            "\u001b[0;34m    :vartype training: bool\u001b[0m\n",
            "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mdump_patches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_version\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"This allows better BC support for :meth:`load_state_dict`. In\u001b[0m\n",
            "\u001b[0;34m    :meth:`state_dict`, the version number will be saved as in the attribute\u001b[0m\n",
            "\u001b[0;34m    `_metadata` of the returned state dict, and thus pickled. `_metadata` is a\u001b[0m\n",
            "\u001b[0;34m    dictionary with keys that follow the naming convention of state dict. See\u001b[0m\n",
            "\u001b[0;34m    ``_load_from_state_dict`` on how to use this information in loading.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m    If new parameters/buffers are added/removed from a module, this number shall\u001b[0m\n",
            "\u001b[0;34m    be bumped, and the module's `_load_from_state_dict` method can compare the\u001b[0m\n",
            "\u001b[0;34m    version number and do appropriate changes if the state dict is from before\u001b[0m\n",
            "\u001b[0;34m    the change.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_backward_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_backward_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_is_full_backward_hook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# Marks whether the corresponding _forward_hooks accept kwargs or not.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# As JIT does not support Set[int], this dict is used as a set, where all\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# hooks represented in this dict accept kwargs.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# forward hooks that should always be called even if an exception is raised\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_forward_hooks_always_called\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# Marks whether the corresponding _forward_hooks accept kwargs or not.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# As JIT does not support Set[int], this dict is used as a set, where all\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# hooks represented in this dict accept kwargs.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_forward_pre_hooks_with_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_load_state_dict_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_state_dict_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_load_state_dict_post_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mcall_super_init\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Initialize internal Module state, shared by both nn.Module and ScriptModule.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"python.nn_module\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# Backward compatibility: no args used to be allowed when call_super_init=False\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_super_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.__init__() got an unexpected keyword argument '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m'\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_super_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.__init__() takes 1 positional argument but \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m were\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\" given\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Calls super().__setattr__('a', a) instead of the typical self.a = a\u001b[0m\n",
            "\u001b[0;34m        to avoid Module.__setattr__ overhead. Module's __setattr__ has special\u001b[0m\n",
            "\u001b[0;34m        handling for parameters, submodules, and buffers but simply calls into\u001b[0m\n",
            "\u001b[0;34m        super().__setattr__ for all other attributes.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_buffers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_non_persistent_buffers_set\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_backward_pre_hooks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_backward_hooks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_is_full_backward_hook\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_forward_hooks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_forward_hooks_with_kwargs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_forward_hooks_always_called\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_forward_pre_hooks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_forward_pre_hooks_with_kwargs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_state_dict_hooks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_state_dict_pre_hooks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_load_state_dict_pre_hooks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_load_state_dict_post_hooks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_modules\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_super_init\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mforward\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_forward_unimplemented\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Add a buffer to the module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This is typically used to register a buffer that should not to be\u001b[0m\n",
            "\u001b[0;34m        considered a model parameter. For example, BatchNorm's ``running_mean``\u001b[0m\n",
            "\u001b[0;34m        is not a parameter, but is part of the module's state. Buffers, by\u001b[0m\n",
            "\u001b[0;34m        default, are persistent and will be saved alongside parameters. This\u001b[0m\n",
            "\u001b[0;34m        behavior can be changed by setting :attr:`persistent` to ``False``. The\u001b[0m\n",
            "\u001b[0;34m        only difference between a persistent buffer and a non-persistent buffer\u001b[0m\n",
            "\u001b[0;34m        is that the latter will not be a part of this module's\u001b[0m\n",
            "\u001b[0;34m        :attr:`state_dict`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Buffers can be accessed as attributes using given names.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            name (str): name of the buffer. The buffer can be accessed\u001b[0m\n",
            "\u001b[0;34m                from this module using the given name\u001b[0m\n",
            "\u001b[0;34m            tensor (Tensor or None): buffer to be registered. If ``None``, then operations\u001b[0m\n",
            "\u001b[0;34m                that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\u001b[0m\n",
            "\u001b[0;34m                the buffer is **not** included in the module's :attr:`state_dict`.\u001b[0m\n",
            "\u001b[0;34m            persistent (bool): whether the buffer is part of this module's\u001b[0m\n",
            "\u001b[0;34m                :attr:`state_dict`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> # xdoctest: +SKIP(\"undefined vars\")\u001b[0m\n",
            "\u001b[0;34m            >>> self.register_buffer('running_mean', torch.zeros(num_features))\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpersistent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ScriptModule does not support non-persistent buffers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_buffers\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot assign buffer before Module.__init__() call\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34mbuffer name should be a string. Got \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'buffer name can\\'t contain \".\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'buffer name can\\'t be empty string \"\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mattribute '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' already exists\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot assign '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' object to buffer '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"(torch Tensor or None required)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_global_buffer_registration_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Add a parameter to the module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The parameter can be accessed as an attribute using given name.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            name (str): name of the parameter. The parameter can be accessed\u001b[0m\n",
            "\u001b[0;34m                from this module using the given name\u001b[0m\n",
            "\u001b[0;34m            param (Parameter or None): parameter to be added to the module. If\u001b[0m\n",
            "\u001b[0;34m                ``None``, then operations that run on parameters, such as :attr:`cuda`,\u001b[0m\n",
            "\u001b[0;34m                are ignored. If ``None``, the parameter is **not** included in the\u001b[0m\n",
            "\u001b[0;34m                module's :attr:`state_dict`.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"cannot assign parameter before Module.__init__() call\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34mparameter name should be a string. Got \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parameter name can\\'t contain \".\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parameter name can\\'t be empty string \"\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mattribute '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' already exists\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot assign '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' object to parameter '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"(torch.nn.Parameter or None required)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34mCannot assign non-leaf Tensor to parameter '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m'. Model \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34mparameters must be created explicitly. To express '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"as a function of another Tensor, compute the value in \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"the forward() method.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_global_parameter_registration_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Add a child module to the current module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The module can be accessed as an attribute using the given name.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            name (str): name of the child module. The child module can be\u001b[0m\n",
            "\u001b[0;34m                accessed from this module using the given name\u001b[0m\n",
            "\u001b[0;34m            module (Module): child module to be added to the module.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m is not a Module subclass\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34mmodule name should be a string. Got \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mattribute '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' already exists\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\u001b[0m\u001b[0;34mmodule name can\\'t contain \".\", got: \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'module name can\\'t be empty string \"\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_global_module_registration_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Alias for :func:`add_module`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_submodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Return the submodule given by ``target`` if it exists, otherwise throw an error.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        For example, let's say you have an ``nn.Module`` ``A`` that\u001b[0m\n",
            "\u001b[0;34m        looks like this:\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. code-block:: text\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            A(\u001b[0m\n",
            "\u001b[0;34m                (net_b): Module(\u001b[0m\n",
            "\u001b[0;34m                    (net_c): Module(\u001b[0m\n",
            "\u001b[0;34m                        (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\u001b[0m\n",
            "\u001b[0;34m                    )\u001b[0m\n",
            "\u001b[0;34m                    (linear): Linear(in_features=100, out_features=200, bias=True)\u001b[0m\n",
            "\u001b[0;34m                )\u001b[0m\n",
            "\u001b[0;34m            )\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\u001b[0m\n",
            "\u001b[0;34m        submodule ``net_b``, which itself has two submodules ``net_c``\u001b[0m\n",
            "\u001b[0;34m        and ``linear``. ``net_c`` then has a submodule ``conv``.)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        To check whether or not we have the ``linear`` submodule, we\u001b[0m\n",
            "\u001b[0;34m        would call ``get_submodule(\"net_b.linear\")``. To check whether\u001b[0m\n",
            "\u001b[0;34m        we have the ``conv`` submodule, we would call\u001b[0m\n",
            "\u001b[0;34m        ``get_submodule(\"net_b.net_c.conv\")``.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The runtime of ``get_submodule`` is bounded by the degree\u001b[0m\n",
            "\u001b[0;34m        of module nesting in ``target``. A query against\u001b[0m\n",
            "\u001b[0;34m        ``named_modules`` achieves the same result, but it is O(N) in\u001b[0m\n",
            "\u001b[0;34m        the number of transitive modules. So, for a simple check to see\u001b[0m\n",
            "\u001b[0;34m        if some submodule exists, ``get_submodule`` should always be\u001b[0m\n",
            "\u001b[0;34m        used.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            target: The fully-qualified string name of the submodule\u001b[0m\n",
            "\u001b[0;34m                to look for. (See above example for how to specify a\u001b[0m\n",
            "\u001b[0;34m                fully-qualified string.)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            torch.nn.Module: The submodule referenced by ``target``\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Raises:\u001b[0m\n",
            "\u001b[0;34m            AttributeError: If the target string references an invalid\u001b[0m\n",
            "\u001b[0;34m                path or resolves to something that is not an\u001b[0m\n",
            "\u001b[0;34m                ``nn.Module``\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0matoms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matoms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" has no \"\u001b[0m \u001b[0;34m\"attribute `\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"` is not \"\u001b[0m \u001b[0;34m\"an nn.Module\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mset_submodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Set the submodule given by ``target`` if it exists, otherwise throw an error.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        For example, let's say you have an ``nn.Module`` ``A`` that\u001b[0m\n",
            "\u001b[0;34m        looks like this:\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. code-block:: text\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            A(\u001b[0m\n",
            "\u001b[0;34m                (net_b): Module(\u001b[0m\n",
            "\u001b[0;34m                    (net_c): Module(\u001b[0m\n",
            "\u001b[0;34m                        (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\u001b[0m\n",
            "\u001b[0;34m                    )\u001b[0m\n",
            "\u001b[0;34m                    (linear): Linear(in_features=100, out_features=200, bias=True)\u001b[0m\n",
            "\u001b[0;34m                )\u001b[0m\n",
            "\u001b[0;34m            )\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\u001b[0m\n",
            "\u001b[0;34m        submodule ``net_b``, which itself has two submodules ``net_c``\u001b[0m\n",
            "\u001b[0;34m        and ``linear``. ``net_c`` then has a submodule ``conv``.)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        To overide the ``Conv2d`` with a new submodule ``Linear``, you\u001b[0m\n",
            "\u001b[0;34m        would call\u001b[0m\n",
            "\u001b[0;34m        ``set_submodule(\"net_b.net_c.conv\", nn.Linear(33, 16))``.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            target: The fully-qualified string name of the submodule\u001b[0m\n",
            "\u001b[0;34m                to look for. (See above example for how to specify a\u001b[0m\n",
            "\u001b[0;34m                fully-qualified string.)\u001b[0m\n",
            "\u001b[0;34m            module: The module to set the submodule to.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Raises:\u001b[0m\n",
            "\u001b[0;34m            ValueError: If the target string is empty\u001b[0m\n",
            "\u001b[0;34m            AttributeError: If the target string references an invalid\u001b[0m\n",
            "\u001b[0;34m                path or resolves to something that is not an\u001b[0m\n",
            "\u001b[0;34m                ``nn.Module``\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot set the submodule without a target name!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0matoms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matoms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matoms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" has no attribute `\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# Use isinstance instead of type here to also handle subclass of nn.Module\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"` is not an nn.Module\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Parameter\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Return the parameter given by ``target`` if it exists, otherwise throw an error.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        See the docstring for ``get_submodule`` for a more detailed\u001b[0m\n",
            "\u001b[0;34m        explanation of this method's functionality as well as how to\u001b[0m\n",
            "\u001b[0;34m        correctly specify ``target``.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            target: The fully-qualified string name of the Parameter\u001b[0m\n",
            "\u001b[0;34m                to look for. (See ``get_submodule`` for how to specify a\u001b[0m\n",
            "\u001b[0;34m                fully-qualified string.)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            torch.nn.Parameter: The Parameter referenced by ``target``\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Raises:\u001b[0m\n",
            "\u001b[0;34m            AttributeError: If the target string references an invalid\u001b[0m\n",
            "\u001b[0;34m                path or resolves to something that is not an\u001b[0m\n",
            "\u001b[0;34m                ``nn.Parameter``\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_submodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" has no attribute `\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparam_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparam_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"` is not an \"\u001b[0m \u001b[0;34m\"nn.Parameter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Tensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Return the buffer given by ``target`` if it exists, otherwise throw an error.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        See the docstring for ``get_submodule`` for a more detailed\u001b[0m\n",
            "\u001b[0;34m        explanation of this method's functionality as well as how to\u001b[0m\n",
            "\u001b[0;34m        correctly specify ``target``.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            target: The fully-qualified string name of the buffer\u001b[0m\n",
            "\u001b[0;34m                to look for. (See ``get_submodule`` for how to specify a\u001b[0m\n",
            "\u001b[0;34m                fully-qualified string.)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            torch.Tensor: The buffer referenced by ``target``\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Raises:\u001b[0m\n",
            "\u001b[0;34m            AttributeError: If the target string references an invalid\u001b[0m\n",
            "\u001b[0;34m                path or resolves to something that is not a\u001b[0m\n",
            "\u001b[0;34m                buffer\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_submodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" has no attribute `\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuffer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mbuffer_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuffer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"` is not a buffer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_extra_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Return any extra state to include in the module's state_dict.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Implement this and a corresponding :func:`set_extra_state` for your module\u001b[0m\n",
            "\u001b[0;34m        if you need to store extra state. This function is called when building the\u001b[0m\n",
            "\u001b[0;34m        module's `state_dict()`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Note that extra state should be picklable to ensure working serialization\u001b[0m\n",
            "\u001b[0;34m        of the state_dict. We only provide provide backwards compatibility guarantees\u001b[0m\n",
            "\u001b[0;34m        for serializing Tensors; other objects may break backwards compatibility if\u001b[0m\n",
            "\u001b[0;34m        their serialized pickled form changes.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            object: Any extra state to store in the module's state_dict\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Reached a code path in Module.get_extra_state() that should never be called. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m\"to report this bug.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mset_extra_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Set extra state contained in the loaded `state_dict`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This function is called from :func:`load_state_dict` to handle any extra state\u001b[0m\n",
            "\u001b[0;34m        found within the `state_dict`. Implement this function and a corresponding\u001b[0m\n",
            "\u001b[0;34m        :func:`get_extra_state` for your module if you need to store extra state within its\u001b[0m\n",
            "\u001b[0;34m        `state_dict`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            state (dict): Extra state from the `state_dict`\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Reached a code path in Module.set_extra_state() that should never be called. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m\"to report this bug.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_compatible_shallow_copy_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# If the new tensor has compatible tensor type as the existing tensor,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# the current behavior is to change the tensor in-place using `.data =`,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# and the future behavior is to overwrite the existing tensor. However,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# changing the current behavior is a BC-breaking change, and we want it\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# to happen in future releases. So for now we introduce the\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# `torch.__future__.get_overwrite_module_params_on_conversion()`\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# global flag to let the user control whether they want the future\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# behavior of overwriting the existing tensor or not.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__future__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_overwrite_module_params_on_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mshould_use_swap_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__future__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_swap_module_params_on_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't want to\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# track autograd history of `param_applied`, so we have to use\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mp_should_use_swap_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mshould_use_swap_tensors\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mparam_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mp_should_use_swap_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mparam_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;31m# Accessing param.grad makes its at::Tensor's use_count 2, which will prevent swapping.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;31m# Decrement use count of the gradient by setting to None\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mparam_applied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mparam_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grad\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34m_apply(): Couldn't swap \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mout_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mp_should_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mout_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32massert\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mout_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_applied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_param\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mparam_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mgrad_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mg_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mparam_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_applied\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mp_should_use_swap_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mgrad_applied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;34mf\"\u001b[0m\u001b[0;34m_apply(): Couldn't swap \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.grad\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mout_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grad\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32melif\u001b[0m \u001b[0mg_should_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32massert\u001b[0m \u001b[0mout_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mout_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_applied\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32massert\u001b[0m \u001b[0mparam_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mout_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_applied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mparam_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Typical use includes initializing the parameters of a model\u001b[0m\n",
            "\u001b[0;34m        (see also :ref:`nn-init-doc`).\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            fn (:class:`Module` -> None): function to be applied to each submodule\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> @torch.no_grad()\u001b[0m\n",
            "\u001b[0;34m            >>> def init_weights(m):\u001b[0m\n",
            "\u001b[0;34m            >>>     print(m)\u001b[0m\n",
            "\u001b[0;34m            >>>     if type(m) == nn.Linear:\u001b[0m\n",
            "\u001b[0;34m            >>>         m.weight.fill_(1.0)\u001b[0m\n",
            "\u001b[0;34m            >>>         print(m.weight)\u001b[0m\n",
            "\u001b[0;34m            >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\u001b[0m\n",
            "\u001b[0;34m            >>> net.apply(init_weights)\u001b[0m\n",
            "\u001b[0;34m            Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m            Parameter containing:\u001b[0m\n",
            "\u001b[0;34m            tensor([[1., 1.],\u001b[0m\n",
            "\u001b[0;34m                    [1., 1.]], requires_grad=True)\u001b[0m\n",
            "\u001b[0;34m            Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m            Parameter containing:\u001b[0m\n",
            "\u001b[0;34m            tensor([[1., 1.],\u001b[0m\n",
            "\u001b[0;34m                    [1., 1.]], requires_grad=True)\u001b[0m\n",
            "\u001b[0;34m            Sequential(\u001b[0m\n",
            "\u001b[0;34m              (0): Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m              (1): Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m            )\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Move all model parameters and buffers to the GPU.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This also makes associated parameters and buffers different objects. So\u001b[0m\n",
            "\u001b[0;34m        it should be called before constructing optimizer if the module will\u001b[0m\n",
            "\u001b[0;34m        live on GPU while being optimized.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            device (int, optional): if specified, all parameters will be\u001b[0m\n",
            "\u001b[0;34m                copied to that device\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Move all model parameters and buffers to the IPU.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This also makes associated parameters and buffers different objects. So\u001b[0m\n",
            "\u001b[0;34m        it should be called before constructing optimizer if the module will\u001b[0m\n",
            "\u001b[0;34m        live on IPU while being optimized.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Arguments:\u001b[0m\n",
            "\u001b[0;34m            device (int, optional): if specified, all parameters will be\u001b[0m\n",
            "\u001b[0;34m                copied to that device\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Move all model parameters and buffers to the XPU.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This also makes associated parameters and buffers different objects. So\u001b[0m\n",
            "\u001b[0;34m        it should be called before constructing optimizer if the module will\u001b[0m\n",
            "\u001b[0;34m        live on XPU while being optimized.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Arguments:\u001b[0m\n",
            "\u001b[0;34m            device (int, optional): if specified, all parameters will be\u001b[0m\n",
            "\u001b[0;34m                copied to that device\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mmtia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Move all model parameters and buffers to the MTIA.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This also makes associated parameters and buffers different objects. So\u001b[0m\n",
            "\u001b[0;34m        it should be called before constructing optimizer if the module will\u001b[0m\n",
            "\u001b[0;34m        live on MTIA while being optimized.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Arguments:\u001b[0m\n",
            "\u001b[0;34m            device (int, optional): if specified, all parameters will be\u001b[0m\n",
            "\u001b[0;34m                copied to that device\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Move all model parameters and buffers to the CPU.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Casts all parameters and buffers to :attr:`dst_type`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            dst_type (type or string): the desired type\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Casts all floating point parameters and buffers to ``float`` datatype.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Casts all floating point parameters and buffers to ``double`` datatype.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Casts all floating point parameters and buffers to ``half`` datatype.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mbfloat16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Casts all floating point parameters and buffers to ``bfloat16`` datatype.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mto_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDeviceLikeType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Move the parameters and buffers to the specified device without copying storage.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            device (:class:`torch.device`): The desired device of the parameters\u001b[0m\n",
            "\u001b[0;34m                and buffers in this module.\u001b[0m\n",
            "\u001b[0;34m            recurse (bool): Whether parameters and buffers of submodules should\u001b[0m\n",
            "\u001b[0;34m                be recursively moved to the specified device.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDeviceLikeType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mnon_blocking\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Move and/or cast the parameters and buffers.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This can be called as\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. function:: to(device=None, dtype=None, non_blocking=False)\u001b[0m\n",
            "\u001b[0;34m           :noindex:\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. function:: to(dtype, non_blocking=False)\u001b[0m\n",
            "\u001b[0;34m           :noindex:\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. function:: to(tensor, non_blocking=False)\u001b[0m\n",
            "\u001b[0;34m           :noindex:\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. function:: to(memory_format=torch.channels_last)\u001b[0m\n",
            "\u001b[0;34m           :noindex:\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\u001b[0m\n",
            "\u001b[0;34m        floating point or complex :attr:`dtype`\\ s. In addition, this method will\u001b[0m\n",
            "\u001b[0;34m        only cast the floating point or complex parameters and buffers to :attr:`dtype`\u001b[0m\n",
            "\u001b[0;34m        (if given). The integral parameters and buffers will be moved\u001b[0m\n",
            "\u001b[0;34m        :attr:`device`, if that is given, but with dtypes unchanged. When\u001b[0m\n",
            "\u001b[0;34m        :attr:`non_blocking` is set, it tries to convert/move asynchronously\u001b[0m\n",
            "\u001b[0;34m        with respect to the host if possible, e.g., moving CPU Tensors with\u001b[0m\n",
            "\u001b[0;34m        pinned memory to CUDA devices.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        See below for examples.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            This method modifies the module in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            device (:class:`torch.device`): the desired device of the parameters\u001b[0m\n",
            "\u001b[0;34m                and buffers in this module\u001b[0m\n",
            "\u001b[0;34m            dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\u001b[0m\n",
            "\u001b[0;34m                the parameters and buffers in this module\u001b[0m\n",
            "\u001b[0;34m            tensor (torch.Tensor): Tensor whose dtype and device are the desired\u001b[0m\n",
            "\u001b[0;34m                dtype and device for all parameters and buffers in this module\u001b[0m\n",
            "\u001b[0;34m            memory_format (:class:`torch.memory_format`): the desired memory\u001b[0m\n",
            "\u001b[0;34m                format for 4D parameters and buffers in this module (keyword\u001b[0m\n",
            "\u001b[0;34m                only argument)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Examples::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\u001b[0m\n",
            "\u001b[0;34m            >>> linear = nn.Linear(2, 2)\u001b[0m\n",
            "\u001b[0;34m            >>> linear.weight\u001b[0m\n",
            "\u001b[0;34m            Parameter containing:\u001b[0m\n",
            "\u001b[0;34m            tensor([[ 0.1913, -0.3420],\u001b[0m\n",
            "\u001b[0;34m                    [-0.5113, -0.2325]])\u001b[0m\n",
            "\u001b[0;34m            >>> linear.to(torch.double)\u001b[0m\n",
            "\u001b[0;34m            Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m            >>> linear.weight\u001b[0m\n",
            "\u001b[0;34m            Parameter containing:\u001b[0m\n",
            "\u001b[0;34m            tensor([[ 0.1913, -0.3420],\u001b[0m\n",
            "\u001b[0;34m                    [-0.5113, -0.2325]], dtype=torch.float64)\u001b[0m\n",
            "\u001b[0;34m            >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\u001b[0m\n",
            "\u001b[0;34m            >>> gpu1 = torch.device(\"cuda:1\")\u001b[0m\n",
            "\u001b[0;34m            >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\u001b[0m\n",
            "\u001b[0;34m            Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m            >>> linear.weight\u001b[0m\n",
            "\u001b[0;34m            Parameter containing:\u001b[0m\n",
            "\u001b[0;34m            tensor([[ 0.1914, -0.3420],\u001b[0m\n",
            "\u001b[0;34m                    [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\u001b[0m\n",
            "\u001b[0;34m            >>> cpu = torch.device(\"cpu\")\u001b[0m\n",
            "\u001b[0;34m            >>> linear.to(cpu)\u001b[0m\n",
            "\u001b[0;34m            Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m            >>> linear.weight\u001b[0m\n",
            "\u001b[0;34m            Parameter containing:\u001b[0m\n",
            "\u001b[0;34m            tensor([[ 0.1914, -0.3420],\u001b[0m\n",
            "\u001b[0;34m                    [-0.5112, -0.2324]], dtype=torch.float16)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\u001b[0m\n",
            "\u001b[0;34m            >>> linear.weight\u001b[0m\n",
            "\u001b[0;34m            Parameter containing:\u001b[0m\n",
            "\u001b[0;34m            tensor([[ 0.3741+0.j,  0.2382+0.j],\u001b[0m\n",
            "\u001b[0;34m                    [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\u001b[0m\n",
            "\u001b[0;34m            >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\u001b[0m\n",
            "\u001b[0;34m            tensor([[0.6122+0.j, 0.1150+0.j],\u001b[0m\n",
            "\u001b[0;34m                    [0.6122+0.j, 0.1150+0.j],\u001b[0m\n",
            "\u001b[0;34m                    [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"nn.Module.to only accepts floating point or complex \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"\u001b[0m\u001b[0;34mdtypes, but got desired dtype=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Complex modules are a new feature under active development whose design may change, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"and some modules might not work as expected when using complex tensors as parameters or buffers. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"if a complex module does not work as expected.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Cannot copy out of meta tensor; no data!\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mwhen moving module from meta to a different device.\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_full_backward_pre_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mprepend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a backward pre-hook on the module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The hook will be called every time the gradients for the module are computed.\u001b[0m\n",
            "\u001b[0;34m        The hook should have the following signature::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            hook(module, grad_output) -> tuple[Tensor] or None\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The :attr:`grad_output` is a tuple. The hook should\u001b[0m\n",
            "\u001b[0;34m        not modify its arguments, but it can optionally return a new gradient with\u001b[0m\n",
            "\u001b[0;34m        respect to the output that will be used in place of :attr:`grad_output` in\u001b[0m\n",
            "\u001b[0;34m        subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\u001b[0m\n",
            "\u001b[0;34m        all non-Tensor arguments.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        For technical reasons, when this hook is applied to a Module, its forward function will\u001b[0m\n",
            "\u001b[0;34m        receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\u001b[0m\n",
            "\u001b[0;34m        of each Tensor returned by the Module's forward function.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. warning ::\u001b[0m\n",
            "\u001b[0;34m            Modifying inputs inplace is not allowed when using backward hooks and\u001b[0m\n",
            "\u001b[0;34m            will raise an error.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            hook (Callable): The user-defined hook to be registered.\u001b[0m\n",
            "\u001b[0;34m            prepend (bool): If true, the provided ``hook`` will be fired before\u001b[0m\n",
            "\u001b[0;34m                all existing ``backward_pre`` hooks on this\u001b[0m\n",
            "\u001b[0;34m                :class:`torch.nn.modules.Module`. Otherwise, the provided\u001b[0m\n",
            "\u001b[0;34m                ``hook`` will be fired after all existing ``backward_pre`` hooks\u001b[0m\n",
            "\u001b[0;34m                on this :class:`torch.nn.modules.Module`. Note that global\u001b[0m\n",
            "\u001b[0;34m                ``backward_pre`` hooks registered with\u001b[0m\n",
            "\u001b[0;34m                :func:`register_module_full_backward_pre_hook` will fire before\u001b[0m\n",
            "\u001b[0;34m                all hooks registered by this method.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            :class:`torch.utils.hooks.RemovableHandle`:\u001b[0m\n",
            "\u001b[0;34m                a handle that can be used to remove the added hook by calling\u001b[0m\n",
            "\u001b[0;34m                ``handle.remove()``\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a backward hook on the module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\u001b[0m\n",
            "\u001b[0;34m        the behavior of this function will change in future versions.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            :class:`torch.utils.hooks.RemovableHandle`:\u001b[0m\n",
            "\u001b[0;34m                a handle that can be used to remove the added hook by calling\u001b[0m\n",
            "\u001b[0;34m                ``handle.remove()``\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Cannot use both regular backward hooks and full backward hooks on a \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"single Module. Please use only one of them.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_full_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mprepend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a backward hook on the module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The hook will be called every time the gradients with respect to a module\u001b[0m\n",
            "\u001b[0;34m        are computed, i.e. the hook will execute if and only if the gradients with\u001b[0m\n",
            "\u001b[0;34m        respect to module outputs are computed. The hook should have the following\u001b[0m\n",
            "\u001b[0;34m        signature::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            hook(module, grad_input, grad_output) -> tuple(Tensor) or None\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\u001b[0m\n",
            "\u001b[0;34m        with respect to the inputs and outputs respectively. The hook should\u001b[0m\n",
            "\u001b[0;34m        not modify its arguments, but it can optionally return a new gradient with\u001b[0m\n",
            "\u001b[0;34m        respect to the input that will be used in place of :attr:`grad_input` in\u001b[0m\n",
            "\u001b[0;34m        subsequent computations. :attr:`grad_input` will only correspond to the inputs given\u001b[0m\n",
            "\u001b[0;34m        as positional arguments and all kwarg arguments are ignored. Entries\u001b[0m\n",
            "\u001b[0;34m        in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\u001b[0m\n",
            "\u001b[0;34m        arguments.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        For technical reasons, when this hook is applied to a Module, its forward function will\u001b[0m\n",
            "\u001b[0;34m        receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\u001b[0m\n",
            "\u001b[0;34m        of each Tensor returned by the Module's forward function.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. warning ::\u001b[0m\n",
            "\u001b[0;34m            Modifying inputs or outputs inplace is not allowed when using backward hooks and\u001b[0m\n",
            "\u001b[0;34m            will raise an error.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            hook (Callable): The user-defined hook to be registered.\u001b[0m\n",
            "\u001b[0;34m            prepend (bool): If true, the provided ``hook`` will be fired before\u001b[0m\n",
            "\u001b[0;34m                all existing ``backward`` hooks on this\u001b[0m\n",
            "\u001b[0;34m                :class:`torch.nn.modules.Module`. Otherwise, the provided\u001b[0m\n",
            "\u001b[0;34m                ``hook`` will be fired after all existing ``backward`` hooks on\u001b[0m\n",
            "\u001b[0;34m                this :class:`torch.nn.modules.Module`. Note that global\u001b[0m\n",
            "\u001b[0;34m                ``backward`` hooks registered with\u001b[0m\n",
            "\u001b[0;34m                :func:`register_module_full_backward_hook` will fire before\u001b[0m\n",
            "\u001b[0;34m                all hooks registered by this method.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            :class:`torch.utils.hooks.RemovableHandle`:\u001b[0m\n",
            "\u001b[0;34m                a handle that can be used to remove the added hook by calling\u001b[0m\n",
            "\u001b[0;34m                ``handle.remove()``\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Cannot use both regular backward hooks and full backward hooks on a \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"single Module. Please use only one of them.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_backward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return the backward hooks for use in the call function.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        It returns two lists, one with the full backward hooks and one with the non-full\u001b[0m\n",
            "\u001b[0;34m        backward hooks.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0m_global_is_full_backward_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mfull_backward_hooks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mfull_backward_hooks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mnon_full_backward_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0m_global_is_full_backward_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_backward_pre_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mbackward_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mbackward_pre_hooks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mbackward_pre_hooks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pre_hooks\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_warn_non_full_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Using non-full backward hooks on a Module that does not return a \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"single Tensor or a tuple of Tensors is deprecated and will be removed \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"in future versions. This hook will be missing some of the grad_output. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Please use register_full_backward_hook to get the documented behavior.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Using non-full backward hooks on a Module that does not take as input a \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"single Tensor or a tuple of Tensors is deprecated and will be removed \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"in future versions. This hook will be missing some of the grad_input. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Please use register_full_backward_hook to get the documented behavior.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# At this point we are sure that inputs and result are tuple of Tensors\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mout_grad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_grad_fn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_grad_fn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgrad_fn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_grad_fn\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Using a non-full backward hook when outputs are nested in python data structure \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"is deprecated and will be removed in future versions. This hook will be missing \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"some grad_output.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_grad_fn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Using a non-full backward hook when outputs are generated by different autograd Nodes \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"is deprecated and will be removed in future versions. This hook will be missing \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"some grad_output. Please use register_full_backward_hook to get the documented behavior.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# At this point the grad_output part of the hook will most likely be correct\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0minputs_grad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mnext_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_functions\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0minputs_grad_fn\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnext_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"is deprecated and will be removed in future versions. This hook will be missing \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"some grad_input. Please use register_full_backward_hook to get the documented \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"behavior.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_forward_pre_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mprepend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mwith_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a forward pre-hook on the module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The hook will be called every time before :func:`forward` is invoked.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        If ``with_kwargs`` is false or not specified, the input contains only\u001b[0m\n",
            "\u001b[0;34m        the positional arguments given to the module. Keyword arguments won't be\u001b[0m\n",
            "\u001b[0;34m        passed to the hooks and only to the ``forward``. The hook can modify the\u001b[0m\n",
            "\u001b[0;34m        input. User can either return a tuple or a single modified value in the\u001b[0m\n",
            "\u001b[0;34m        hook. We will wrap the value into a tuple if a single value is returned\u001b[0m\n",
            "\u001b[0;34m        (unless that value is already a tuple). The hook should have the\u001b[0m\n",
            "\u001b[0;34m        following signature::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            hook(module, args) -> None or modified input\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        If ``with_kwargs`` is true, the forward pre-hook will be passed the\u001b[0m\n",
            "\u001b[0;34m        kwargs given to the forward function. And if the hook modifies the\u001b[0m\n",
            "\u001b[0;34m        input, both the args and kwargs should be returned. The hook should have\u001b[0m\n",
            "\u001b[0;34m        the following signature::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            hook (Callable): The user defined hook to be registered.\u001b[0m\n",
            "\u001b[0;34m            prepend (bool): If true, the provided ``hook`` will be fired before\u001b[0m\n",
            "\u001b[0;34m                all existing ``forward_pre`` hooks on this\u001b[0m\n",
            "\u001b[0;34m                :class:`torch.nn.modules.Module`. Otherwise, the provided\u001b[0m\n",
            "\u001b[0;34m                ``hook`` will be fired after all existing ``forward_pre`` hooks\u001b[0m\n",
            "\u001b[0;34m                on this :class:`torch.nn.modules.Module`. Note that global\u001b[0m\n",
            "\u001b[0;34m                ``forward_pre`` hooks registered with\u001b[0m\n",
            "\u001b[0;34m                :func:`register_module_forward_pre_hook` will fire before all\u001b[0m\n",
            "\u001b[0;34m                hooks registered by this method.\u001b[0m\n",
            "\u001b[0;34m                Default: ``False``\u001b[0m\n",
            "\u001b[0;34m            with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\u001b[0m\n",
            "\u001b[0;34m                given to the forward function.\u001b[0m\n",
            "\u001b[0;34m                Default: ``False``\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            :class:`torch.utils.hooks.RemovableHandle`:\u001b[0m\n",
            "\u001b[0;34m                a handle that can be used to remove the added hook by calling\u001b[0m\n",
            "\u001b[0;34m                ``handle.remove()``\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks_with_kwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwith_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks_with_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mprepend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mwith_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0malways_call\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a forward hook on the module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The hook will be called every time after :func:`forward` has computed an output.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        If ``with_kwargs`` is ``False`` or not specified, the input contains only\u001b[0m\n",
            "\u001b[0;34m        the positional arguments given to the module. Keyword arguments won't be\u001b[0m\n",
            "\u001b[0;34m        passed to the hooks and only to the ``forward``. The hook can modify the\u001b[0m\n",
            "\u001b[0;34m        output. It can modify the input inplace but it will not have effect on\u001b[0m\n",
            "\u001b[0;34m        forward since this is called after :func:`forward` is called. The hook\u001b[0m\n",
            "\u001b[0;34m        should have the following signature::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            hook(module, args, output) -> None or modified output\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        If ``with_kwargs`` is ``True``, the forward hook will be passed the\u001b[0m\n",
            "\u001b[0;34m        ``kwargs`` given to the forward function and be expected to return the\u001b[0m\n",
            "\u001b[0;34m        output possibly modified. The hook should have the following signature::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            hook(module, args, kwargs, output) -> None or modified output\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            hook (Callable): The user defined hook to be registered.\u001b[0m\n",
            "\u001b[0;34m            prepend (bool): If ``True``, the provided ``hook`` will be fired\u001b[0m\n",
            "\u001b[0;34m                before all existing ``forward`` hooks on this\u001b[0m\n",
            "\u001b[0;34m                :class:`torch.nn.modules.Module`. Otherwise, the provided\u001b[0m\n",
            "\u001b[0;34m                ``hook`` will be fired after all existing ``forward`` hooks on\u001b[0m\n",
            "\u001b[0;34m                this :class:`torch.nn.modules.Module`. Note that global\u001b[0m\n",
            "\u001b[0;34m                ``forward`` hooks registered with\u001b[0m\n",
            "\u001b[0;34m                :func:`register_module_forward_hook` will fire before all hooks\u001b[0m\n",
            "\u001b[0;34m                registered by this method.\u001b[0m\n",
            "\u001b[0;34m                Default: ``False``\u001b[0m\n",
            "\u001b[0;34m            with_kwargs (bool): If ``True``, the ``hook`` will be passed the\u001b[0m\n",
            "\u001b[0;34m                kwargs given to the forward function.\u001b[0m\n",
            "\u001b[0;34m                Default: ``False``\u001b[0m\n",
            "\u001b[0;34m            always_call (bool): If ``True`` the ``hook`` will be run regardless of\u001b[0m\n",
            "\u001b[0;34m                whether an exception is raised while calling the Module.\u001b[0m\n",
            "\u001b[0;34m                Default: ``False``\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            :class:`torch.utils.hooks.RemovableHandle`:\u001b[0m\n",
            "\u001b[0;34m                a handle that can be used to remove the added hook by calling\u001b[0m\n",
            "\u001b[0;34m                ``handle.remove()``\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mextra_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwith_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0malways_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mtracing_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtracing_state\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptMethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_module_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# type ignore was added because at this point one knows that\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# torch.jit._trace._trace_module_map is not Optional and has type Dict[Any, Any]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_module_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_module_map\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# type: ignore[index, operator] # noqa: B950\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mcalled_always_called_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mnonlocal\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mbackward_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mbackward_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_backward_pre_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_backward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mhook_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m*\u001b[0m\u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks_with_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0margs_kwargs_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0margs_kwargs_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_kwargs_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_kwargs_result\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs_kwargs_result\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34m\"forward pre-hook must return None or a tuple \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34mf\"\u001b[0m\u001b[0;34mof (new_args, new_kwargs), but got \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0margs_kwargs_result\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0margs_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0margs_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0margs_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs_result\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mbw_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mfull_backward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbackward_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mbw_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackwardHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mhook_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# mark that always called hook is run\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_global_forward_hooks_always_called\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mcalled_always_called_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For backward hooks to be called,\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                  \u001b[0;34m\" module output should be a Tensor or a tuple of Tensors\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                  \u001b[0;34mf\"\u001b[0m\u001b[0;34m but received \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_output_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# Handle the non-full backward hooks\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mgrad_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WrappedHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_warn_non_full_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_compiling\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# This is technically not behavior equivalent when compiling, but it's\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# incredibly unlikely we will ever support throwing an exception in NN\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# module, and then catching it here, and then reraising it, and then\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# catching it again, and expecting the resulting frame to be compiled.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# The reraise here just gunks up our exception handling for no good\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# reason.  Don't try to run the always called hooks in event of\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# exception.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mis_compiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# run always called hooks if they have not already been run\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# For now only forward hooks have the always_call option but perhaps\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# this functionality should be added to full backward hooks as well.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mhook_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_global_forward_hooks_always_called\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcalled_always_called_hooks\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[possibly-undefined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[possibly-undefined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"global module forward hook with ``always_call=True`` raised an exception \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                      \u001b[0;34mf\"\u001b[0m\u001b[0;34mthat was silenced as another error was raised in forward: \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mhook_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcalled_always_called_hooks\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[possibly-undefined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[possibly-undefined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[possibly-undefined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"module forward hook with ``always_call=True`` raised an exception \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                      \u001b[0;34mf\"\u001b[0m\u001b[0;34mthat was silenced as another error was raised in forward: \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# raise exception raised in try block\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# fmt: on\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m__call__\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapped_call_impl\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_compiled_call_impl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# Support loading old checkpoints that don't have the following attrs:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_forward_pre_hooks\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_forward_pre_hooks_with_kwargs\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks_with_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_forward_hooks_with_kwargs\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_forward_hooks_always_called\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_state_dict_hooks\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_state_dict_pre_hooks\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_load_state_dict_pre_hooks\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_load_state_dict_post_hooks\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_post_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_non_persistent_buffers_set\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_is_full_backward_hook\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_backward_pre_hooks\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# On the return type:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# This is done for better interop with various type checkers for the end users.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# Having a stricter return type doesn't play nicely with `register_buffer()` and forces\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# people to excessively use type-ignores, asserts, casts, etc.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# See full discussion on the problems with returning `Union` here\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# https://github.com/microsoft/pyright/issues/4213\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_buffers\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0m_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_buffers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"_modules\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_modules\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"\u001b[0m\u001b[0;34m'\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' object has no attribute '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m'\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mremove_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts_or_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts_or_sets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mdel\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"cannot assign parameters before Module.__init__() call\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mremove_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot assign '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' as parameter '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"(torch.nn.Parameter or None expected)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_modules\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"cannot assign module before Module.__init__() call\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mremove_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_global_module_registration_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot assign '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' as child module '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"(torch.nn.Module or None expected)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_global_module_registration_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_buffers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot assign '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' as buffer '\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m' \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"(torch.nn.Buffer, torch.Tensor or None expected)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mpersistent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mpersistent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# === HACK ===\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# This whole block below should just be:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# self.register_buffer(name, value, persistent)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# But to support subclasses of nn.Module that (wrongfully) implement a\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# register_buffer() method that doesn't have the \"persistent\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# argument. Only pass it in if it is accepted otherwise assume\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# it is always true\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0msign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0;34m\"persistent\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34m\"Registering a non-persistent buffer \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34m\"on a Module subclass that implements \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34m\"register_buffer() without the persistent \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34m\"argument is not allowed.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;31m# Assume that the implementation without the argument has the\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;31m# behavior from before the argument was added: persistent=True\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# === HACK END ===\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_register_state_dict_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a post-hook for the :meth:`~torch.nn.Module.state_dict` method.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        It should have the following signature::\u001b[0m\n",
            "\u001b[0;34m            hook(module, state_dict, prefix, local_metadata) -> None or state_dict\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The registered hooks can modify the ``state_dict`` inplace or return a new one.\u001b[0m\n",
            "\u001b[0;34m        If a new ``state_dict`` is returned, it will only be respected if it is the root\u001b[0m\n",
            "\u001b[0;34m        module that :meth:`~nn.Module.state_dict` is called from.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_from_public_api\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Cannot register the same function as the state dict post hook that was \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"previously registered via register_state_dict_post_hook\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_state_dict_post_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a post-hook for the :meth:`~torch.nn.Module.state_dict` method.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        It should have the following signature::\u001b[0m\n",
            "\u001b[0;34m            hook(module, state_dict, prefix, local_metadata) -> None\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The registered hooks can modify the ``state_dict`` inplace.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# In _register_state_dict_hook there was a bug described in\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# https://github.com/pytorch/pytorch/issues/117437 where the return value\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# was only respected for the root module but not child submodules.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# We fix this in this public version by only allowing inplace modifications on\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# the state_dict by the hook. However, since hooks registered via both these\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# APIs will be added to `_state_dict_hooks` and the type of `_state_dict_hooks`\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# cannot be changed due to many dependencies on it, we mark a hook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# as being registered via the public API by setting `_from_public_api` on it.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# In the implementation of `state_dict`, if the callable does not have this\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# flag, the old behavior of respecting the return value will be preserved\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# for the root module, otherwise, we ensure that the hook returns None.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_public_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_state_dict_pre_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a pre-hook for the :meth:`~torch.nn.Module.state_dict` method.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        It should have the following signature::\u001b[0m\n",
            "\u001b[0;34m            hook(module, prefix, keep_vars) -> None\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The registered hooks can be used to perform pre-processing before the ``state_dict``\u001b[0m\n",
            "\u001b[0;34m        call is made.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_pre_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_save_to_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Save module state to the `destination` dictionary.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The `destination` dictionary will contain the state\u001b[0m\n",
            "\u001b[0;34m        of the module, but not its descendants. This is called on every\u001b[0m\n",
            "\u001b[0;34m        submodule in :meth:`~torch.nn.Module.state_dict`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        In rare cases, subclasses can achieve class-specific behavior by\u001b[0m\n",
            "\u001b[0;34m        overriding this method with custom logic.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            destination (dict): a dict where state will be stored\u001b[0m\n",
            "\u001b[0;34m            prefix (str): the prefix for parameters and buffers used in this\u001b[0m\n",
            "\u001b[0;34m                module\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mdestination\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep_vars\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mdestination\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep_vars\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mextra_state_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_EXTRA_STATE_KEY_SUFFIX\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_extra_state\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extra_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extra_state\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mdestination\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextra_state_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extra_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# The user can pass an optional arbitrary mappable object to `state_dict`, in which case `state_dict` returns\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# back that same object. But if they pass nothing, an `OrderedDict` is created and returned.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mT_destination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"T_destination\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT_destination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_destination\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# TODO: Change `*args` to `*` and remove the corresponding warning in docs when BC allows.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;31m# Also remove the logic for arg parsing together.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return a dictionary containing references to the whole state of the module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Both parameters and persistent buffers (e.g. running averages) are\u001b[0m\n",
            "\u001b[0;34m        included. Keys are corresponding parameter and buffer names.\u001b[0m\n",
            "\u001b[0;34m        Parameters and buffers set to ``None`` are not included.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            The returned object is a shallow copy. It contains references\u001b[0m\n",
            "\u001b[0;34m            to the module's parameters and buffers.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. warning::\u001b[0m\n",
            "\u001b[0;34m            Currently ``state_dict()`` also accepts positional arguments for\u001b[0m\n",
            "\u001b[0;34m            ``destination``, ``prefix`` and ``keep_vars`` in order. However,\u001b[0m\n",
            "\u001b[0;34m            this is being deprecated and keyword arguments will be enforced in\u001b[0m\n",
            "\u001b[0;34m            future releases.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. warning::\u001b[0m\n",
            "\u001b[0;34m            Please avoid the use of argument ``destination`` as it is not\u001b[0m\n",
            "\u001b[0;34m            designed for end-users.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            destination (dict, optional): If provided, the state of module will\u001b[0m\n",
            "\u001b[0;34m                be updated into the dict and the same object is returned.\u001b[0m\n",
            "\u001b[0;34m                Otherwise, an ``OrderedDict`` will be created and returned.\u001b[0m\n",
            "\u001b[0;34m                Default: ``None``.\u001b[0m\n",
            "\u001b[0;34m            prefix (str, optional): a prefix added to parameter and buffer\u001b[0m\n",
            "\u001b[0;34m                names to compose the keys in state_dict. Default: ``''``.\u001b[0m\n",
            "\u001b[0;34m            keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\u001b[0m\n",
            "\u001b[0;34m                returned in the state dict are detached from autograd. If it's\u001b[0m\n",
            "\u001b[0;34m                set to ``True``, detaching will not be performed.\u001b[0m\n",
            "\u001b[0;34m                Default: ``False``.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            dict:\u001b[0m\n",
            "\u001b[0;34m                a dictionary containing a whole state of the module\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> # xdoctest: +SKIP(\"undefined vars\")\u001b[0m\n",
            "\u001b[0;34m            >>> module.state_dict().keys()\u001b[0m\n",
            "\u001b[0;34m            ['bias', 'weight']\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# TODO: Remove `args` and the parsing logic when BC allows.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# DeprecationWarning is ignored by default\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Positional args are being deprecated, use kwargs instead. Refer to \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\" for details.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mdestination\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkeep_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mkeep_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdestination\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mdestination\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mlocal_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mdestination\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_to_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mkeep_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_from_public_api\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"state_dict post-hook must return None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_register_load_state_dict_pre_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"See :meth:`~torch.nn.Module.register_load_state_dict_pre_hook` for details.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        A subtle difference is that if ``with_module`` is set to ``False``, then the\u001b[0m\n",
            "\u001b[0;34m        hook will not take the ``module`` as the first argument whereas\u001b[0m\n",
            "\u001b[0;34m        :meth:`~torch.nn.Module.register_load_state_dict_pre_hook` always takes the\u001b[0m\n",
            "\u001b[0;34m        ``module`` as the first argument.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Arguments:\u001b[0m\n",
            "\u001b[0;34m            hook (Callable): Callable hook that will be invoked before\u001b[0m\n",
            "\u001b[0;34m                loading the state dict.\u001b[0m\n",
            "\u001b[0;34m            with_module (bool, optional): Whether or not to pass the module\u001b[0m\n",
            "\u001b[0;34m                instance to the hook as the first parameter.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WrappedHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_module\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_load_state_dict_pre_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a pre-hook to be run before module's :meth:`~nn.Module.load_state_dict` is called.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        It should have the following signature::\u001b[0m\n",
            "\u001b[0;34m            hook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs) -> None  # noqa: B950\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Arguments:\u001b[0m\n",
            "\u001b[0;34m            hook (Callable): Callable hook that will be invoked before\u001b[0m\n",
            "\u001b[0;34m                loading the state dict.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_load_state_dict_pre_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_load_state_dict_post_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Register a post-hook to be run after module's :meth:`~nn.Module.load_state_dict` is called.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        It should have the following signature::\u001b[0m\n",
            "\u001b[0;34m            hook(module, incompatible_keys) -> None\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The ``module`` argument is the current module that this hook is registered\u001b[0m\n",
            "\u001b[0;34m        on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\u001b[0m\n",
            "\u001b[0;34m        of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\u001b[0m\n",
            "\u001b[0;34m        is a ``list`` of ``str`` containing the missing keys and\u001b[0m\n",
            "\u001b[0;34m        ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        The given incompatible_keys can be modified inplace if needed.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Note that the checks performed when calling :func:`load_state_dict` with\u001b[0m\n",
            "\u001b[0;34m        ``strict=True`` are affected by modifications the hook makes to\u001b[0m\n",
            "\u001b[0;34m        ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\u001b[0m\n",
            "\u001b[0;34m        set of keys will result in an error being thrown when ``strict=True``, and\u001b[0m\n",
            "\u001b[0;34m        clearing out both missing and unexpected keys will avoid an error.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            :class:`torch.utils.hooks.RemovableHandle`:\u001b[0m\n",
            "\u001b[0;34m                a handle that can be used to remove the added hook by calling\u001b[0m\n",
            "\u001b[0;34m                ``handle.remove()``\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_post_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_post_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0munexpected_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Copy parameters and buffers from :attr:`state_dict` into only this module, but not its descendants.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This is called on every submodule\u001b[0m\n",
            "\u001b[0;34m        in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\u001b[0m\n",
            "\u001b[0;34m        module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\u001b[0m\n",
            "\u001b[0;34m        For state dicts without metadata, :attr:`local_metadata` is empty.\u001b[0m\n",
            "\u001b[0;34m        Subclasses can achieve class-specific backward compatible loading using\u001b[0m\n",
            "\u001b[0;34m        the version number at `local_metadata.get(\"version\", None)`.\u001b[0m\n",
            "\u001b[0;34m        Additionally, :attr:`local_metadata` can also contain the key\u001b[0m\n",
            "\u001b[0;34m        `assign_to_params_buffers` that indicates whether keys should be\u001b[0m\n",
            "\u001b[0;34m        assigned their corresponding tensor in the state_dict.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. note::\u001b[0m\n",
            "\u001b[0;34m            :attr:`state_dict` is not the same object as the input\u001b[0m\n",
            "\u001b[0;34m            :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\u001b[0m\n",
            "\u001b[0;34m            it can be modified.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            state_dict (dict): a dict containing parameters and\u001b[0m\n",
            "\u001b[0;34m                persistent buffers.\u001b[0m\n",
            "\u001b[0;34m            prefix (str): the prefix for parameters and buffers used in this\u001b[0m\n",
            "\u001b[0;34m                module\u001b[0m\n",
            "\u001b[0;34m            local_metadata (dict): a dict containing the metadata for this module.\u001b[0m\n",
            "\u001b[0;34m                See\u001b[0m\n",
            "\u001b[0;34m            strict (bool): whether to strictly enforce that the keys in\u001b[0m\n",
            "\u001b[0;34m                :attr:`state_dict` with :attr:`prefix` match the names of\u001b[0m\n",
            "\u001b[0;34m                parameters and buffers in this module\u001b[0m\n",
            "\u001b[0;34m            missing_keys (list of str): if ``strict=True``, add missing keys to\u001b[0m\n",
            "\u001b[0;34m                this list\u001b[0m\n",
            "\u001b[0;34m            unexpected_keys (list of str): if ``strict=True``, add unexpected\u001b[0m\n",
            "\u001b[0;34m                keys to this list\u001b[0m\n",
            "\u001b[0;34m            error_msgs (list of str): error messages should be added to this\u001b[0m\n",
            "\u001b[0;34m                list, and will be reported together in\u001b[0m\n",
            "\u001b[0;34m                :meth:`~torch.nn.Module.load_state_dict`\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0munexpected_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mpersistent_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mlocal_name_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersistent_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mlocal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_name_params\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0massign_to_params_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"assign_to_params_buffers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0muse_swap_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__future__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_swap_module_params_on_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0minput_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0merror_msgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf'\u001b[0m\u001b[0;34mWhile copying the parameter named \"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\", \u001b[0m\u001b[0;34m'\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"expected torch.Tensor or Tensor-like object from checkpoint but \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mreceived \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# This is used to avoid copying uninitialized parameters into\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# non-lazy modules, since they dont have the hook to do the checks\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# in such case, it will error when accessing the .shape attribute.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mis_param_lazy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_lazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;31m# Backward compatibility: loading 1-dim tensor from 0.3.* to version 0.4+\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mnot\u001b[0m \u001b[0mis_param_lazy\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0minput_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_param_lazy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# local shape should match the one in checkpoint\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0merror_msgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34msize mismatch for \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m: copying a param with shape \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m from checkpoint, \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mthe shape in current model is \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0massign_to_params_buffers\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mfor \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m: copying from a non-meta parameter in the checkpoint to a meta \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"parameter in the current model, which is a no-op. (Did you mean to \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"pass `assign=True` to assign items in the state dictionary to their \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"corresponding key in the module instead of copying them in place?)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0muse_swap_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0mnew_input_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0minput_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massign_to_params_buffers\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_input_param\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0mnew_input_param\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34m\"module_load returned one of self or other, please .detach() \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34m\"the result if returning one of the inputs in module_load\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_input_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0mnew_input_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                        \u001b[0mnew_input_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                        \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0mnew_input_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_input_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;32mdel\u001b[0m \u001b[0mnew_input_param\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32melif\u001b[0m \u001b[0massign_to_params_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;31m# Shape checks are already done above\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0minput_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                        \u001b[0minput_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                                    \u001b[0minput_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"swapping\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swap_tensors\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"copying\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0merror_msgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf'\u001b[0m\u001b[0;34mWhile \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m the parameter named \"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\", \u001b[0m\u001b[0;34m'\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mwhose dimensions in the model are \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m and \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mwhose dimensions in the checkpoint are \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m, \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34man exception occurred : \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmissing_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mextra_state_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_EXTRA_STATE_KEY_SUFFIX\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_extra_state\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_extra_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_extra_state\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mextra_state_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_extra_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextra_state_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmissing_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_state_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mextra_state_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0munexpected_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_state_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mextra_state_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0minput_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;31m# Must be Module if it have attributes\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                            \u001b[0munexpected_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32melif\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0munexpected_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        If :attr:`strict` is ``True``, then\u001b[0m\n",
            "\u001b[0;34m        the keys of :attr:`state_dict` must exactly match the keys returned\u001b[0m\n",
            "\u001b[0;34m        by this module's :meth:`~torch.nn.Module.state_dict` function.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        .. warning::\u001b[0m\n",
            "\u001b[0;34m            If :attr:`assign` is ``True`` the optimizer must be created after\u001b[0m\n",
            "\u001b[0;34m            the call to :attr:`load_state_dict` unless\u001b[0m\n",
            "\u001b[0;34m            :func:`~torch.__future__.get_swap_module_params_on_conversion` is ``True``.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            state_dict (dict): a dict containing parameters and\u001b[0m\n",
            "\u001b[0;34m                persistent buffers.\u001b[0m\n",
            "\u001b[0;34m            strict (bool, optional): whether to strictly enforce that the keys\u001b[0m\n",
            "\u001b[0;34m                in :attr:`state_dict` match the keys returned by this module's\u001b[0m\n",
            "\u001b[0;34m                :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\u001b[0m\n",
            "\u001b[0;34m            assign (bool, optional): When ``False``, the properties of the tensors\u001b[0m\n",
            "\u001b[0;34m                in the current module are preserved while when ``True``, the\u001b[0m\n",
            "\u001b[0;34m                properties of the Tensors in the state dict are preserved. The only\u001b[0m\n",
            "\u001b[0;34m                exception is the ``requires_grad`` field of :class:`~torch.nn.Parameter`s\u001b[0m\n",
            "\u001b[0;34m                for which the value from the module is preserved.\u001b[0m\n",
            "\u001b[0;34m                Default: ``False``\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\u001b[0m\n",
            "\u001b[0;34m                * **missing_keys** is a list of str containing any keys that are expected\u001b[0m\n",
            "\u001b[0;34m                    by this module but missing from the provided ``state_dict``.\u001b[0m\n",
            "\u001b[0;34m                * **unexpected_keys** is a list of str containing the keys that are not\u001b[0m\n",
            "\u001b[0;34m                    expected by this module but present in the provided ``state_dict``.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Note:\u001b[0m\n",
            "\u001b[0;34m            If a parameter or buffer is registered as ``None`` and its corresponding key\u001b[0m\n",
            "\u001b[0;34m            exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\u001b[0m\n",
            "\u001b[0;34m            ``RuntimeError``.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"\u001b[0m\u001b[0;34mExpected state_dict to be dict-like, got \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmissing_keys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0munexpected_keys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0merror_msgs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_metadata\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# mypy isn't aware that \"_metadata\" exists in state_dict\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mlocal_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"assign_to_params_buffers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mlocal_state_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0munexpected_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mchild_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mchild_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_state_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_prefix\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: F821\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mincompatible_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincompatible_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32massert\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Hooks registered with ``register_load_state_dict_post_hook`` are not\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"expected to return new values, if incompatible_keys need to be modified,\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"it should be done inplace.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mdel\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0merror_msgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Unexpected key(s) in state_dict: {}. \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0merror_msgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Missing key(s) in state_dict: {}. \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Error(s) in loading state_dict for {}:\\n\\t{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Help yield various names + members of modules.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodule_prefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32myield\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return an iterator over module parameters.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This is typically passed to an optimizer.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            recurse (bool): if True, then yields parameters of this module\u001b[0m\n",
            "\u001b[0;34m                and all submodules. Otherwise, yields only parameters that\u001b[0m\n",
            "\u001b[0;34m                are direct members of this module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Yields:\u001b[0m\n",
            "\u001b[0;34m            Parameter: module parameter\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> # xdoctest: +SKIP(\"undefined vars\")\u001b[0m\n",
            "\u001b[0;34m            >>> for param in model.parameters():\u001b[0m\n",
            "\u001b[0;34m            >>>     print(type(param), param.size())\u001b[0m\n",
            "\u001b[0;34m            <class 'torch.Tensor'> (20L,)\u001b[0m\n",
            "\u001b[0;34m            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            prefix (str): prefix to prepend to all parameter names.\u001b[0m\n",
            "\u001b[0;34m            recurse (bool): if True, then yields parameters of this module\u001b[0m\n",
            "\u001b[0;34m                and all submodules. Otherwise, yields only parameters that\u001b[0m\n",
            "\u001b[0;34m                are direct members of this module.\u001b[0m\n",
            "\u001b[0;34m            remove_duplicate (bool, optional): whether to remove the duplicated\u001b[0m\n",
            "\u001b[0;34m                parameters in the result. Defaults to True.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Yields:\u001b[0m\n",
            "\u001b[0;34m            (str, Parameter): Tuple containing the name and parameter\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> # xdoctest: +SKIP(\"undefined vars\")\u001b[0m\n",
            "\u001b[0;34m            >>> for name, param in self.named_parameters():\u001b[0m\n",
            "\u001b[0;34m            >>>     if name in ['bias']:\u001b[0m\n",
            "\u001b[0;34m            >>>         print(param.size())\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mlambda\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_duplicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return an iterator over module buffers.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            recurse (bool): if True, then yields buffers of this module\u001b[0m\n",
            "\u001b[0;34m                and all submodules. Otherwise, yields only buffers that\u001b[0m\n",
            "\u001b[0;34m                are direct members of this module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Yields:\u001b[0m\n",
            "\u001b[0;34m            torch.Tensor: module buffer\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> # xdoctest: +SKIP(\"undefined vars\")\u001b[0m\n",
            "\u001b[0;34m            >>> for buf in model.buffers():\u001b[0m\n",
            "\u001b[0;34m            >>>     print(type(buf), buf.size())\u001b[0m\n",
            "\u001b[0;34m            <class 'torch.Tensor'> (20L,)\u001b[0m\n",
            "\u001b[0;34m            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mnamed_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            prefix (str): prefix to prepend to all buffer names.\u001b[0m\n",
            "\u001b[0;34m            recurse (bool, optional): if True, then yields buffers of this module\u001b[0m\n",
            "\u001b[0;34m                and all submodules. Otherwise, yields only buffers that\u001b[0m\n",
            "\u001b[0;34m                are direct members of this module. Defaults to True.\u001b[0m\n",
            "\u001b[0;34m            remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Yields:\u001b[0m\n",
            "\u001b[0;34m            (str, torch.Tensor): Tuple containing the name and buffer\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> # xdoctest: +SKIP(\"undefined vars\")\u001b[0m\n",
            "\u001b[0;34m            >>> for name, buf in self.named_buffers():\u001b[0m\n",
            "\u001b[0;34m            >>>     if name in ['running_var']:\u001b[0m\n",
            "\u001b[0;34m            >>>         print(buf.size())\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mlambda\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_duplicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return an iterator over immediate children modules.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Yields:\u001b[0m\n",
            "\u001b[0;34m            Module: a child module\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Yields:\u001b[0m\n",
            "\u001b[0;34m            (str, Module): Tuple containing a name and child module\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> # xdoctest: +SKIP(\"undefined vars\")\u001b[0m\n",
            "\u001b[0;34m            >>> for name, module in model.named_children():\u001b[0m\n",
            "\u001b[0;34m            >>>     if name in ['conv4', 'conv5']:\u001b[0m\n",
            "\u001b[0;34m            >>>         print(module)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32myield\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return an iterator over all modules in the network.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Yields:\u001b[0m\n",
            "\u001b[0;34m            Module: a module in the network\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Note:\u001b[0m\n",
            "\u001b[0;34m            Duplicate modules are returned only once. In the following\u001b[0m\n",
            "\u001b[0;34m            example, ``l`` will be returned only once.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> l = nn.Linear(2, 2)\u001b[0m\n",
            "\u001b[0;34m            >>> net = nn.Sequential(l, l)\u001b[0m\n",
            "\u001b[0;34m            >>> for idx, m in enumerate(net.modules()):\u001b[0m\n",
            "\u001b[0;34m            ...     print(idx, '->', m)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            0 -> Sequential(\u001b[0m\n",
            "\u001b[0;34m              (0): Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m              (1): Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m            )\u001b[0m\n",
            "\u001b[0;34m            1 -> Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            memo: a memo to store the set of modules already added to the result\u001b[0m\n",
            "\u001b[0;34m            prefix: a prefix that will be added to the name of the module\u001b[0m\n",
            "\u001b[0;34m            remove_duplicate: whether to remove the duplicated module instances in the result\u001b[0m\n",
            "\u001b[0;34m                or not\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Yields:\u001b[0m\n",
            "\u001b[0;34m            (str, Module): Tuple of name and module\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Note:\u001b[0m\n",
            "\u001b[0;34m            Duplicate modules are returned only once. In the following\u001b[0m\n",
            "\u001b[0;34m            example, ``l`` will be returned only once.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Example::\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            >>> l = nn.Linear(2, 2)\u001b[0m\n",
            "\u001b[0;34m            >>> net = nn.Sequential(l, l)\u001b[0m\n",
            "\u001b[0;34m            >>> for idx, m in enumerate(net.named_modules()):\u001b[0m\n",
            "\u001b[0;34m            ...     print(idx, '->', m)\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m            0 -> ('', Sequential(\u001b[0m\n",
            "\u001b[0;34m              (0): Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m              (1): Linear(in_features=2, out_features=2, bias=True)\u001b[0m\n",
            "\u001b[0;34m            ))\u001b[0m\n",
            "\u001b[0;34m            1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmemo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Set the module in training mode.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This has any effect only on certain modules. See documentations of\u001b[0m\n",
            "\u001b[0;34m        particular modules for details of their behaviors in training/evaluation\u001b[0m\n",
            "\u001b[0;34m        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\u001b[0m\n",
            "\u001b[0;34m        etc.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            mode (bool): whether to set training mode (``True``) or evaluation\u001b[0m\n",
            "\u001b[0;34m                         mode (``False``). Default: ``True``.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training mode is expected to be boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Set the module in evaluation mode.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This has any effect only on certain modules. See documentations of\u001b[0m\n",
            "\u001b[0;34m        particular modules for details of their behaviors in training/evaluation\u001b[0m\n",
            "\u001b[0;34m        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\u001b[0m\n",
            "\u001b[0;34m        etc.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        See :ref:`locally-disable-grad-doc` for a comparison between\u001b[0m\n",
            "\u001b[0;34m        `.eval()` and several similar mechanisms that may be confused with it.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Change if autograd should record operations on parameters in this module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This method sets the parameters' :attr:`requires_grad` attributes\u001b[0m\n",
            "\u001b[0;34m        in-place.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This method is helpful for freezing part of the module for finetuning\u001b[0m\n",
            "\u001b[0;34m        or training parts of a model individually (e.g., GAN training).\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        See :ref:`locally-disable-grad-doc` for a comparison between\u001b[0m\n",
            "\u001b[0;34m        `.requires_grad_()` and several similar mechanisms that may be confused with it.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            requires_grad (bool): whether autograd should record operations on\u001b[0m\n",
            "\u001b[0;34m                                  parameters in this module. Default: ``True``.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Module: self\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_to_none\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Reset gradients of all model parameters.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        See similar function under :class:`torch.optim.Optimizer` for more context.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            set_to_none (bool): instead of setting to zero, set the grads to None.\u001b[0m\n",
            "\u001b[0;34m                See :meth:`torch.optim.Optimizer.zero_grad` for details.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_replica\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Calling .zero_grad() from a module created with nn.DataParallel() has no effect. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"The parameters are copied (in a differentiable manner) from the original module. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"This means they are not leaf nodes in autograd and so don't accumulate gradients. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;34m\"If you need gradients in your forward method, consider using autograd.grad instead.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mset_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                        \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                    \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"See :meth:`torch.Tensor.share_memory_`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_memory_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Set the extra representation of the module.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        To print customized extra information, you should re-implement\u001b[0m\n",
            "\u001b[0;34m        this method in your own modules. Both single-line and multi-line\u001b[0m\n",
            "\u001b[0;34m        strings are acceptable.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# We treat the extra repr like the sub-module, one item per line\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mextra_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mextra_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# empty string will be split into list ['']\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mextra_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mchild_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmod_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mmod_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_addindent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mchild_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"): \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmod_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_lines\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchild_lines\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmain_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"(\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;31m# simple one-liner info, which most builtin Modules will use\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_lines\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchild_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmain_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mextra_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m                \u001b[0mmain_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n  \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n  \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmain_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\")\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmain_str\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmodule_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_attrs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# Eliminate attrs that are not legal Python variable names\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_replicate_for_data_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mreplica\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mreplica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# replicas do not have parameters themselves, the replicas reference the original\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# module.\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mreplica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mreplica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mreplica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mreplica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_replica\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mreplica\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Compile this Module's forward using :func:`torch.compile`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        This Module's `__call__` method is compiled and all arguments are passed as-is\u001b[0m\n",
            "\u001b[0;34m        to :func:`torch.compile`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        See :func:`torch.compile` for details on the arguments for this function.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFile:\u001b[0m           /nix/store/8gmhah54y2p2r01hd0xnmdkvwh03819a-python3.12-torch-2.5.1/lib/python3.12/site-packages/torch/nn/modules/module.py\n",
            "\u001b[0;31mType:\u001b[0m           type\n",
            "\u001b[0;31mSubclasses:\u001b[0m     Identity, Linear, Bilinear, Threshold, ReLU, RReLU, Hardtanh, Sigmoid, Hardsigmoid, Tanh, ..."
          ]
        }
      ],
      "source": [
        "torch.nn.Module??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3odUxKDa7jbq"
      },
      "source": [
        "## Torch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw3ACW-eyIYE"
      },
      "source": [
        "At the core of PyTorch there is the `Tensor` class. It is very much like numpy's arrays, but supports autograd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxMMJ1tO7jbq",
        "outputId": "61675b34-d95d-4722-e426-dae8d3a1ea2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate a tensor of size 2x3x4\n",
        "t = torch.Tensor(2, 3, 4)\n",
        "type(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3xcTvfc7jbr",
        "outputId": "387061b7-c9d2-4c81-e9cc-f93a6f580e72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the size of the tensor\n",
        "t.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDV8gZtQyIYK"
      },
      "source": [
        "# Tensors and tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okM52HiDyIYL",
        "outputId": "a6d17835-c677-47f1-cbde-7cf9d61da241"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.Tensor(2, 3, 4)\n",
        "type(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BTJlKPWyIYL",
        "outputId": "c459a1cc-1b00-461e-ca30-b6ff2656e8cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pusVGlb5yIYL",
        "outputId": "b98ca6a3-45dc-4378-edee-08977c17cdc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[2.8843e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObX2wLyCyIYL",
        "outputId": "e5aef7a0-1746-4b5c-cf12-d9f0756ccecc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1 = torch.tensor([1, 2, 3, 4])\n",
        "type(t1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sll5NbsTyIYL",
        "outputId": "74424481-e4f1-4deb-c83a-dc8d7cd17c72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYJJkp2FyIYL",
        "outputId": "345e6006-4748-481b-d93b-af93028517ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVoVwZLByIYM",
        "outputId": "a5cdf7e6-9ab2-4671-914c-4ac9a257b99e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t2 = torch.tensor([[[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]], [[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]]])\n",
        "type(t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y306ZdIXyIYM",
        "outputId": "8b000625-518a-488e-d007-d139a7db7fdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3, 4],\n",
              "         [1, 2, 3, 4],\n",
              "         [1, 2, 3, 4]],\n",
              "\n",
              "        [[1, 2, 3, 4],\n",
              "         [1, 2, 3, 4],\n",
              "         [1, 2, 3, 4]]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwPWsVjqyIYM",
        "outputId": "6c58ea3b-ed30-4e8b-f824-300875124a7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60fsUROsyIYM",
        "outputId": "4e87ed2c-642b-4544-b74f-37e53e289912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.zeros(2, 3, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-enxHw_JaeZJ"
      },
      "source": [
        "# Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXAmpH-Z7jbr",
        "outputId": "376e74b1-f526-46bb-888d-20475283d4de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "point in a 24 dimensional space\n",
            "organised in 3 sub-dimensions\n"
          ]
        }
      ],
      "source": [
        "t = torch.Tensor(2, 3, 4)\n",
        "# prints dimensional space and sub-dimensions\n",
        "print(f'point in a {t.numel()} dimensional space')\n",
        "print(f'organised in {t.dim()} sub-dimensions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBq6Q4F8TGpJ"
      },
      "source": [
        "> Don't confuse a 3D vector with a 3D tensor. _Dimensionality_ can refer to either the number of entries along a specific axis (as in a 3D vector) or the number of axes in a tensor (such as a 3D tensor), which can be confusing. You may also come across the term _tensor of rank_ 3, where rank refers to the number of axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC8XADcV7jbr",
        "outputId": "d12e76d0-a3f8-4552-8d64-b66829a48f01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 1.4013e-45,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  8.4078e-45,  0.0000e+00],\n",
              "         [ 1.4013e-45,  0.0000e+00, -1.7014e+38,  1.1515e-40]]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ARC3wOQ7jbr",
        "outputId": "f861d4b5-8643-4cd2-aded-ddb08b2ad474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[3., 2., 8., 4.],\n",
              "         [4., 0., 2., 2.],\n",
              "         [1., 6., 5., 2.]],\n",
              "\n",
              "        [[4., 9., 9., 5.],\n",
              "         [0., 3., 9., 2.],\n",
              "         [4., 1., 1., 2.]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mind the underscore!\n",
        "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
        "# For example: x.copy_(y), x.t_(), x.random_(n) will change x.\n",
        "t.random_(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL2ajaMg7jbs",
        "outputId": "ae1e7d14-4192-49d1-9c12-7d9b3668655c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3., 2., 8., 4., 4., 0., 2., 2.],\n",
              "        [1., 6., 5., 2., 4., 9., 9., 5.],\n",
              "        [0., 3., 9., 2., 4., 1., 1., 2.]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r = t.view(3, 8) # r is the Tensor reshaped to the size 3x8\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivViPVSG7jbs",
        "outputId": "df99de28-fe2a-45c2-9488-9b16f317c0d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# As you can see zero_ would replace r with 0's which was originally filled with integers\n",
        "r.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7KuYVw17jbs",
        "outputId": "c9734794-f0f4-49c8-c950-3d99a68d176d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIhTq4nIdqx7",
        "outputId": "6be3ea9e-7329-4f06-c804-c39323585716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12, 4, 1) (8, 1)\n",
            "torch.Size([2, 3, 4]) torch.Size([3, 8])\n"
          ]
        }
      ],
      "source": [
        "# What are strides. And how are they related to shapes?\n",
        "print(t.stride(), r.stride())\n",
        "print(t.shape, r.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uum4hxYkffli",
        "outputId": "a6803271-65e2-4d60-d8e9-231aeb55907c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[5., 4., 4., 8.],\n",
              "         [7., 8., 9., 9.],\n",
              "         [3., 3., 3., 8.]],\n",
              "\n",
              "        [[2., 0., 4., 8.],\n",
              "         [3., 9., 7., 1.],\n",
              "         [4., 5., 4., 0.]]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's try that again without doing the operations in place\n",
        "t.random_(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJM4es_M-p2Y",
        "outputId": "f5aab4b7-70cc-49b3-e930-489f85b9f6eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Not in place\n",
        "r = t.view(3, 8)\n",
        "r = torch.zeros_like(r)\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivw8wI5U-12D",
        "outputId": "f3d1af00-8062-4e96-c0b9-003758311aed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[5., 4., 4., 8.],\n",
              "         [7., 8., 9., 9.],\n",
              "         [3., 3., 3., 8.]],\n",
              "\n",
              "        [[2., 0., 4., 8.],\n",
              "         [3., 9., 7., 1.],\n",
              "         [4., 5., 4., 0.]]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJdGqvwTdiMs",
        "outputId": "5713c6c6-ffb3-45d1-e42b-2db1f68d03aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12, 4, 1) (8, 1)\n"
          ]
        }
      ],
      "source": [
        "# What are strides?\n",
        "print(t.stride(), r.stride())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "p6Fcui7u7jbs"
      },
      "outputs": [],
      "source": [
        "# This *is* important\n",
        "s = r.clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm9a0zci7jbt",
        "outputId": "a2463ad9-32de-4710-8b4b-9cd06afa0b79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# In-place fill of 1's\n",
        "s.fill_(1)\n",
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1K3hywm7jbt",
        "outputId": "a5d21449-5ccd-4918-a6b5-cb881375eb7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Because we cloned r, even though we did an in-place operation, this doesn't affect r\n",
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir1URH3v7jbt"
      },
      "source": [
        "## Vectors (1D Tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRCvA1R17jbt",
        "outputId": "f6bf895e-dfd7-446c-84ca-457282f2a5f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creates a 1D tensor of integers 1 to 4\n",
        "v = torch.Tensor([1, 2, 3, 4])\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmkSLrIi7jbt",
        "outputId": "7640bf03-1728-4c91-92cf-ca06fb226b92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dim: 1, size: 4\n"
          ]
        }
      ],
      "source": [
        "# Print number of dimensions (1D) and size of tensor\n",
        "print(f'dim: {v.dim()}, size: {v.size()[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K03oi68R7jbu",
        "outputId": "73d83678-2cca-484e-ea0c-0f831f0c4a5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 0., 2., 0.])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.Tensor([1, 0, 2, 0])\n",
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGGpVC_b7jbu",
        "outputId": "c7f48242-ae13-40e3-e05d-992aec024e19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 0., 6., 0.])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Element-wise multiplication\n",
        "v * w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq7-Aqs_7jbu",
        "outputId": "5fe812c4-43eb-4f78-fc45-8fd81af68166"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Scalar (dot) product: 1*1 + 2*0 + 3*2 + 4*0\n",
        "v @ w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-oXbFTO7jbu",
        "outputId": "55bd2fcf-129b-40f7-ee8f-4c213108094c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([9., 6., 2., 5., 7.])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# In-place replacement of random number from 0 to 10\n",
        "x = torch.Tensor(5).random_(10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00BUa-L47jbu",
        "outputId": "1f2c8001-c27a-4a2f-d2fb-79415529e7cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first: 9.0, last: 7.0\n"
          ]
        }
      ],
      "source": [
        "print(f'first: {x[0]}, last: {x[-1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX_Uy_T17jbu",
        "outputId": "07f19af2-0cf6-4a7b-ce16-fa488d66d28b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6., 2.])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract sub-Tensor [from:to)\n",
        "x[1:2 + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPNJt5Kt7jbv",
        "outputId": "1e0be6dd-42bb-466b-e479-5b1ec7a0477a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor with integers ranging from 1 to 4 (both included)\n",
        "v = torch.arange(1, 5)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_nwZPg-7jbv",
        "outputId": "3a73d7a8-e779-41c9-e150-e6e0a8c73db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 1,  4,  9, 16]) tensor([1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Square all elements in the tensor\n",
        "print(v.pow(2), v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De7wobZv7jbv"
      },
      "source": [
        "## Matrices (2D Tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuiyP0MK7jbv",
        "outputId": "0e24b697-c974-4993-8417-a52a325893d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a 2x4 tensor\n",
        "m = torch.Tensor([[2, 5, 3, 7],\n",
        "                  [4, 2, 1, 9]])\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI36U8sv7jbv",
        "outputId": "0eb37690-2005-4e6d-d058-ce82913b1b0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.dim()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f91z4dw7jbw",
        "outputId": "28dbd276-d461-45fa-ea07-23405a11a262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 -- 4 -- torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "print(m.size(0), m.size(1), m.size(), sep=' -- ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vuLnT2z7jbw",
        "outputId": "ed1e81c6-b8a8-4373-83bb-d1c026a0c3e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Indexing row 0, column 2 (0-indexed)\n",
        "m[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLIC7pG97jbw",
        "outputId": "b3682945-6231-4958-ac3d-0600ddfac6f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Indexing row 0, column 2 (0-indexed)\n",
        "m[0, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsutF_zc7jbw",
        "outputId": "7ae29333-d753-439c-8ba8-2aea3eb7a545"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5., 2.])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Indexing column 1, all rows (returns size 2)\n",
        "m[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLg24cHx7jbw",
        "outputId": "e0055f61-067f-41a4-a001-4456a9dcff3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5.],\n",
              "        [2.]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Indexing column 1, all rows (returns size 2x1)\n",
        "m[:, [1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8nu79EU7jbx",
        "outputId": "50d8a977-3c73-4a5b-89f3-fd418e4e7891"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Indexes row 0, all columns (returns 1x4)\n",
        "m[[0], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYVpTC7l7jbx",
        "outputId": "4f1ea149-66ca-422a-d197-40af8654ff32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensor of numbers from 1 to 5)\n",
        "v = torch.arange(1., 5)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UQd3S3w7jbx",
        "outputId": "46380650-b31a-4224-fe35-21db94deec6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c10o4XUQ7jbx",
        "outputId": "55fa9b6c-663a-4f4d-d8d0-bbea504fa567"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([49., 47.])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Scalar product\n",
        "m @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEkCtsZG7jbx",
        "outputId": "8dd167d2-9b6a-4e81-b5ef-82a8ed560eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(49.)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculated by 1*2 + 2*5 + 3*3 + 4*7\n",
        "m[0, :] @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzxKEjus7jby",
        "outputId": "f83475d1-4a7a-4442-a414-ed1b05871f74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([47.])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculated by\n",
        "m[[1], :] @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP7c5qI17jby",
        "outputId": "a0c36a00-c7b9-44cd-f823-58c649797cda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.7007, 5.9600, 3.6861, 7.8141],\n",
              "        [4.3358, 2.6148, 1.0579, 9.8002]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add a random tensor of size 2x4 to m\n",
        "m + torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nli9YIb17jby",
        "outputId": "4df6cfa9-7ad6-469f-8b11-b1c91ac520db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.3210, 4.6893, 2.1215, 6.0554],\n",
              "        [3.1749, 1.8874, 0.1037, 8.0571]])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subtract a random tensor of size 2x4 to m\n",
        "m - torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0QPbbr87jby",
        "outputId": "fd2b460d-9e0c-4890-b9d1-186478c49e1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8686, 1.7633, 2.4050, 4.3127],\n",
              "        [3.6106, 0.3012, 0.4609, 5.4205]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiply a random tensor of size 2x4 to m\n",
        "m * torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRxwhq3p7jby",
        "outputId": "22a846ea-a556-48de-fd40-45fe99fe6a09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 4.5203,  6.6099, 12.3662,  8.8771],\n",
              "        [ 7.2270,  2.7082,  1.7907, 30.5952]])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Divide m by a random tensor of size 2x4\n",
        "m / torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFjUamkg7jby",
        "outputId": "85cbfcf7-0085-4bb7-e49a-d942abcac98f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88uWT_-N7jbz",
        "outputId": "cd69f865-4ce5-4a1c-8c9b-0a9b0b72147d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 4.],\n",
              "        [5., 2.],\n",
              "        [3., 1.],\n",
              "        [7., 9.]])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transpose tensor m, which is essentially 2x4 to 4x2\n",
        "m.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfx8uRtl7jbz",
        "outputId": "f48806d2-771e-405b-8abf-07a1f5f0d3aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 4.],\n",
              "        [5., 2.],\n",
              "        [3., 1.],\n",
              "        [7., 9.]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Same as\n",
        "m.transpose(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "7FKRAnqU9JrZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 4.],\n",
              "        [5., 2.],\n",
              "        [3., 1.],\n",
              "        [7., 9.]])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Same as\n",
        "m.transpose(1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p2bHHeHJewn"
      },
      "source": [
        "## Broadcasting\n",
        "\n",
        "Two tensors are “broadcastable” if the following rules hold:\n",
        "\n",
        "*   Each tensor has at least one dimension.\n",
        "*   When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "pPyg44mxJeHP"
      },
      "outputs": [],
      "source": [
        "x=torch.empty(5,7,3)\n",
        "y=torch.empty(5,7,3)\n",
        "# x and y are broadcastable since all dimensions are equal\n",
        "\n",
        "x=torch.empty((0,))\n",
        "y=torch.empty(2,2)\n",
        "# x and y are not broadcastable, because x does not have at least 1 dimension\n",
        "\n",
        "x=torch.empty(5,3,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are broadcastable.\n",
        "# 1st trailing dimension: both have size 1\n",
        "# 2nd trailing dimension: y has size 1\n",
        "# 3rd trailing dimension: x size == y size\n",
        "# 4th trailing dimension: y dimension doesn't exist\n",
        "\n",
        "# but:\n",
        "x=torch.empty(5,2,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpudbDP9MI4U",
        "outputId": "99e161d6-5474-4472-fcc4-e71529f667ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 4, 1])\n",
            "torch.Size([3, 1, 7])\n"
          ]
        }
      ],
      "source": [
        "# How is the output dimension calculated?\n",
        "x=torch.empty(5,1,4,1)\n",
        "y=torch.empty(3,1,1)\n",
        "print((x+y).size())\n",
        "\n",
        "x=torch.empty(1)\n",
        "y=torch.empty(3,1,7)\n",
        "print((x+y).size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpCZhT8U7jbz"
      },
      "source": [
        "## Constructors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYn7XeYu7jbz",
        "outputId": "ea3ba7ba-0c61-48a9-902c-ed0780d3adbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 4., 5., 6., 7., 8.])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensor from 3 to 8\n",
        "torch.arange(3., 8 + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH8X7Dts7jbz",
        "outputId": "6c757fc1-86b7-47c1-a64a-f4c6f24795da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5.7000,  2.7000, -0.3000])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensor from 5.7 to -2.1 with step -3\n",
        "torch.arange(5.7, -2.1, -3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B14Dyrn7jbz",
        "outputId": "80df78a3-58f5-4cb9-f751-1ee490640a94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3.0000, 3.2632, 3.5263, 3.7895, 4.0526, 4.3158, 4.5789, 4.8421, 5.1053,\n",
              "         5.3684, 5.6316, 5.8947, 6.1579, 6.4211, 6.6842, 6.9474, 7.2105, 7.4737,\n",
              "         7.7368, 8.0000]])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# returns a 1D tensor of equally spaced elements between start=3, end=8 and number of elements=20\n",
        "torch.linspace(3, 8, 20).view(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb4KEmjU7jb0",
        "outputId": "7f310060-7ffb-4daa-e3f5-717e52b78fbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor filled with 0's\n",
        "torch.zeros(3, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrOxrng27jb0",
        "outputId": "a5985151-403f-4ac0-8f12-8592021c4fbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]]])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor filled with 1's\n",
        "torch.ones(3, 2, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt6VUo1A7jb0",
        "outputId": "3d97b3eb-08f7-4da6-d4e7-5449e47887a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor with the diagonal filled with 1\n",
        "torch.eye(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "oDCnuhOf7jb0"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "81dgFtq67jb0",
        "outputId": "53e98426-964e-4ad0-cb99-3e4d43975519"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Numpy bridge!\n",
        "plt.hist(torch.randn(1000).numpy(), 100);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "pBhx09297jb1",
        "outputId": "53d2d199-ed4d-4436-8e9b-edc3ddd554b6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(torch.randn(10**6).numpy(), 100);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyeN3wTV7jb1"
      },
      "source": [
        "## Casting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "MxMGbcNP7jb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.BFloat16Tensor\n",
            "torch.BoolTensor\n",
            "torch.ByteTensor\n",
            "torch.CharTensor\n",
            "torch.DoubleTensor\n",
            "torch.FloatTensor\n",
            "torch.HalfTensor\n",
            "torch.IntTensor\n",
            "torch.LongTensor\n",
            "torch.ShortTensor\n",
            "torch.Tensor"
          ]
        }
      ],
      "source": [
        "# Helper to get what kind of tensor types\n",
        "torch.*Tensor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6pXTH4b7jb1",
        "outputId": "0935e246-ba51-4981-ae28-892b5273494d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = torch.Tensor([[2, 5, 3, 7],\n",
        "                  [4, 2, 1, 9]])\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TAG0hTN7jb2",
        "outputId": "9f01ee0a-cf76-4c76-fba0-fd15bf3c9ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This is basically a 64 bit float tensor\n",
        "m_double = m.double()\n",
        "m_double"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFe9nMZi7jb2",
        "outputId": "55d8232c-32aa-4a36-ced3-090b5b577817"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5, 3, 7],\n",
              "        [4, 2, 1, 9]], dtype=torch.uint8)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This creates a tensor of type int8\n",
        "m_byte = m.byte()\n",
        "m_byte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSVzhX_I7jb2",
        "outputId": "b41d85b8-f518-43cf-8947-2783ed095196"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2., 5., 3., 7.],\n",
              "       [4., 2., 1., 9.]], dtype=float32)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Converts tensor to numpy array\n",
        "m_np = m.numpy()\n",
        "m_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHfSv9BB7jb2",
        "outputId": "93494fdc-5e7a-4722-9dcf-4098c0ad8c30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.,  5.,  3.,  7.],\n",
              "       [ 4.,  2.,  1.,  9.]], dtype=float32)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# In-place fill of column 0 and row 0 with value -1\n",
        "m_np[0, 0] = -1\n",
        "m_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICAeMZLU7jb3",
        "outputId": "88b60fca-9940-4100-e11e-b22f54d439cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.,  5.,  3.,  7.],\n",
              "        [ 4.,  2.,  1.,  9.]])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CStd3ORV7jb3",
        "outputId": "4688c3b0-2067-4b47-ff83-6270d790c8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4] tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor of integers ranging from 0 to 4\n",
        "import numpy as np\n",
        "n_np = np.arange(5)\n",
        "n = torch.from_numpy(n_np)\n",
        "print(n_np, n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gGi0E-h7jb3",
        "outputId": "03c69de0-891e-41bb-ca9f-3c275d688cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 2 4 6 8] tensor([0, 2, 4, 6, 8])\n"
          ]
        }
      ],
      "source": [
        "# In-place multiplication of all elements by 2 for tensor n\n",
        "n.mul_(2)\n",
        "print(n_np, n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yGGuawb7jb3"
      },
      "source": [
        "## Using the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "V3cSABmzDda2"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "GPU is not enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[85], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If this cell fails you need to change the runtime of your colab notebook to GPU\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Go to Runtime -> Change Runtime Type and select GPU\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU is not enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# use the first gpu available if possible\u001b[39;00m\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAssertionError\u001b[0m: GPU is not enabled"
          ]
        }
      ],
      "source": [
        "# If this cell fails you need to change the runtime of your colab notebook to GPU\n",
        "# Go to Runtime -> Change Runtime Type and select GPU\n",
        "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
        "\n",
        "# use the first gpu available if possible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rQvVYDMFIAW",
        "outputId": "26e105e6-1e38-4fdc-e72b-edf8c873c23e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor's device: cpu\n",
            "tensor's device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Tensors can be moved between gpu and cpu memory\n",
        "\n",
        "tensor = torch.randn(5, 5) # create a 5x5 matrix filled with random numbers\n",
        "print(f\"tensor's device: {tensor.device}\") # by default tensors are stored in cpu memory (RAM)\n",
        "\n",
        "# Move your tensor to GPU device 0 if there is one (first GPU in the system)\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(device) # tensor.cuda() is an alternative although not recommended\n",
        "print(f\"tensor's device: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "ccZpZ5xzZ8Sy",
        "outputId": "ad98cbc5-59a8-4f21-b3f1-1836f154e567"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# A common mistake\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m2\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[43mdevice\u001b[49m)\n\u001b[1;32m      3\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# This throws an exception, since you can't operate on tensors stored in\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# different devices, and the error message is pretty clear about that\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "# A common mistake\n",
        "a = torch.randn(5, 2, device=device)\n",
        "b = torch.randn(1, 2)\n",
        "\n",
        "# This throws an exception, since you can't operate on tensors stored in\n",
        "# different devices, and the error message is pretty clear about that\n",
        "c = a * b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x59Bo0QnEUOU"
      },
      "source": [
        "# Gradient Computation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H25IsxuRKlry",
        "outputId": "1a083fda-e145-4ec7-fb26-c1cddc971a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient of L with respecto to a: tensor([36., 81.])\n"
          ]
        }
      ],
      "source": [
        "# Tensors also track the operations applied on them in order to differentiate them\n",
        "\n",
        "# setting requires_grad to true tells the autograd engine that we want to compute\n",
        "# gradients for this tensor\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "\n",
        "L = 3*a**3\n",
        "L.sum().backward()  # Convert to scalar before back-propagation\n",
        "print(f\"Gradient of L with respecto to a: {a.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnviODjmRdKC"
      },
      "source": [
        "Lets check if the computed gradients are correct:\n",
        "\n",
        "$\\frac{\\partial{L}}{\\partial{a}} = [9 * a_1^2, 9 * a_2^2]$\n",
        "\n",
        "$\\frac{\\partial{L}}{\\partial{a}} = [9 * 2^2, 9 * 3^2]$\n",
        "\n",
        "$\\frac{\\partial{L}}{\\partial{a}} = [36, 81]$\n",
        "\n",
        "As we can see the gradient vector matches the one computed by the autograd engine (no surprise there)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61qpDwtvU_E8",
        "outputId": "b369444a-16c0-46b4-8278-19c2fde4db09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Does a require gradients? : False\n",
            "Does b require gradients?: True\n"
          ]
        }
      ],
      "source": [
        "# Notice that the output tensor of an operation will require gradients even\n",
        "# if only a single input tensor has requires_grad=True.\n",
        "\n",
        "x = torch.rand(5, 5)\n",
        "y = torch.rand(5, 5)\n",
        "z = torch.rand((5, 5), requires_grad=True)\n",
        "\n",
        "a = x + y\n",
        "print(f\"Does a require gradients? : {a.requires_grad}\")\n",
        "b = x + z\n",
        "print(f\"Does b require gradients?: {b.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq_YCBR4yIYI"
      },
      "source": [
        "# Autograd with Pytorch: Repeat previous exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsBFjVXQO_jA"
      },
      "source": [
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Let's repeat with PyTorch one of the gradient calculations what we already did before outselves (with our own auto-differentiation engine):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN2Jff2gyIYI",
        "outputId": "c1ab9c96-69f9-4a3e-d81f-fa064c3a8f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result = tensor(28., grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor(4.0, requires_grad = True)  # a = 4\n",
        "b = torch.tensor(3.0, requires_grad = True)  # b = 3\n",
        "c = a + b        # c = 4 + 3\n",
        "\n",
        "res = a * c      # res = a * c = 28\n",
        "\n",
        "print(\"Result =\", res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hfDIYY5yIYJ"
      },
      "source": [
        "See the warning that the next cell will produce:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwt2meXeyIYJ",
        "outputId": "dccb457b-c78a-4a2e-903e-e7912cb4034b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The derivative of the result with respect to a is: tensor(11.)\n",
            "The derivative of the result with respect to b is: tensor(4.)\n",
            "The derivative of the result with respect to c is: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/nix-shell.UaHmdM/ipykernel_14224/2763502806.py:8: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /build/pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"The derivative of the result with respect to c is:\", c.grad)\n"
          ]
        }
      ],
      "source": [
        "# Call backprop on the result\n",
        "res.backward()\n",
        "\n",
        "# Now all variables should contain in their \"grad\" the derivative d(res) / d(variable)\n",
        "print(\"The derivative of the result with respect to a is:\", a.grad)\n",
        "print(\"The derivative of the result with respect to b is:\", b.grad)\n",
        "# Also for intermediate results\n",
        "print(\"The derivative of the result with respect to c is:\", c.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chEBBK46yIYJ"
      },
      "source": [
        "There are three different things to understand here. PyTorch by default only calculates gradients for the leaf nodes of the computation graph. To do that, all nodes that are necessary for the computation require their gradient to be computed, but the gradient is not maintained, they do not have a `grad` variable. We can ask PyTorch to create a `grad` variable and save the gradient in these intermediate nodes though, if for some reason we are interested in accessing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB3ybQNhyIYJ",
        "outputId": "a845b39c-354b-4fca-d632-f85bf217780b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO5g_uAXyIYK",
        "outputId": "2d5e46b3-4265-4bd0-8923-94c6d4f1a41e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.retains_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xyteFnUyIYK",
        "outputId": "dc90b960-c509-4571-f5e6-1c1bbbca8956"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.is_leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxPwYuI3yIYK",
        "outputId": "56bd5726-47da-40ec-8d1c-729aa45764a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requires Grad: True\tRetains Grad: True\tIs leaf: False\n"
          ]
        }
      ],
      "source": [
        "c.retain_grad()\n",
        "\n",
        "print(f\"Requires Grad: {c.requires_grad}\\tRetains Grad: {c.retains_grad}\\tIs leaf: {c.is_leaf}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1uxcO-1yIYK",
        "outputId": "b912f6b3-204d-4721-b87e-05cd2a2e8714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result = tensor(28., grad_fn=<MulBackward0>)\n",
            "The derivative of the result with respect to a is: tensor(11.)\n",
            "The derivative of the result with respect to b is: tensor(4.)\n",
            "The derivative of the result with respect to c is: tensor(4.)\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor(4.0, requires_grad = True)  # a = 4\n",
        "b = torch.tensor(3.0, requires_grad = True)  # b = 3\n",
        "c = a + b        # c = 4 + 3\n",
        "c.retain_grad()\n",
        "\n",
        "res = a * c      # res = a * c = 28\n",
        "\n",
        "print(\"Result =\", res)\n",
        "\n",
        "# Call backprop on the result\n",
        "res.backward()\n",
        "\n",
        "# Now all variables should contain in their \"grad\" the derivative d(res) / d(variable)\n",
        "print(\"The derivative of the result with respect to a is:\", a.grad)\n",
        "print(\"The derivative of the result with respect to b is:\", b.grad)\n",
        "# Also for intermediate results\n",
        "print(\"The derivative of the result with respect to c is:\", c.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-_70bB17jb4"
      },
      "source": [
        "## Much more\n",
        "\n",
        "There's definitely much more, but this was the basics about `Tensor`s fun.\n",
        "\n",
        "*Torch* full API can be found [here](https://pytorch.org/docs/stable/index.html).\n",
        "You'll find 100+ `Tensor` operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xl6U-RoEtY3"
      },
      "source": [
        "# Homework\n",
        "\n",
        "<font color=\"blue\">**Exercise 1:** The code below simulates a tiny neural network, however it throws an exception. As you build neural networks in PyTorch you will see this exception often. Look at the error message, explain whats happening and make the necessary changes to the code to get an output from this tiny network</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "5aGsG2MMGebg",
        "outputId": "15e0ffad-1f5c-487f-d8bf-80eb47533c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4490,  0.3699,  0.1368,  0.2974,  0.5646],\n",
            "        [-0.3858,  0.0381,  1.2865,  0.4263, -1.0048],\n",
            "        [-0.5296, -0.0190,  1.4845,  0.4485, -1.2751],\n",
            "        [ 1.3148,  0.7140, -1.0556,  0.1637,  2.1922],\n",
            "        [-1.1953, -0.2836,  2.4014,  0.5513, -2.5266]])\n",
            "torch.Size([5, 5]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # Set the random seed so things are predictable\n",
        "\n",
        "# Features are 5 random normal variables\n",
        "features = torch.randn((1, 5))\n",
        "# True weights for our data, random normal variables again\n",
        "weights = torch.randn_like(features)\n",
        "# and a true bias term\n",
        "bias = torch.randn((1, 1))\n",
        "fts = torch.mm(features.T, weights)\n",
        "print(fts + bias)\n",
        "print(fts.shape, bias.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoV3PxbRyIYY"
      },
      "source": [
        "<font color=\"blue\">**Exercise 2:** Once you manage to sucessfully run the code above notice how the shape of the tensors ```fts``` and ```bias``` are drastically different, yet they can be added together. Which internal PyTorch mechanism makes this addition happen?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZrd2J_WyIYY"
      },
      "source": [
        "---\n",
        "\n",
        "Broadcasting was used :D\n",
        "\n",
        "We can see that the shapes are broadcasting compatible.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8N-hhzmQZaA"
      },
      "source": [
        "# More Homework\n",
        "\n",
        "<font color=\"blue\">**Exercise 3:** Answer the following questions about the cell below</font>\n",
        "\n",
        "1. Does the value of ```t``` change? Why?\n",
        "2. Does the shape of ```t``` change? Why?\n",
        "3. Explain, in your own words. What is the stride of a tensor, why is it convenient to have them?\n",
        "4.  Pick a mathematical operation like cosine or square root (not those though 🙂). Can you find the correspoding function in the [torch library](https://https://pytorch.org/docs/stable/torch.html#pointwise-ops).\n",
        "5. Apply the function element-wise to ```a```.\n",
        "6. Is there a version of the function that operates in place? Does it return an error? Why? How can it be fixed?\n",
        "7. Run the same function on the GPU. Do you notice any difference in runtime? If not, why do you think that is?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "__SC70eiXYn1",
        "outputId": "353cc339-699b-475f-9228-caee3c436e2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t = tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  2,  4],\n",
              "        [ 6,  8, 10],\n",
              "        [12, 14, 16]])"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.tensor(list(range(9)))\n",
        "print(f'{t = }')\n",
        "\n",
        "a = t.view(3, 3)\n",
        "a.mul_(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Yes, it changes. Because using the `view` method, we are not making a deep copy of the tensor, they share the same memory.\n",
        "2. It does not change, since that is the purpose of the `view` method, for tensor to share their values but not their shape or functionality.\n",
        "3. The stride is used to iterate efficiently over a tensor, as we can know how many positions to jump in memory. Depending on the datatype of the tensor we a specific amount of bytes.\n",
        "4. `torch.nn.functional.sigmoid`\n",
        "5. Code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5000, 0.8808, 0.9820],\n",
              "        [0.9975, 0.9997, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000]])"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn.functional import sigmoid\n",
        "a_sigmoid = sigmoid(a)\n",
        "a_sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5000, 0.8808, 0.9820],\n",
              "        [0.9975, 0.9997, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000]])"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.sigmoid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. On the GPU :D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
